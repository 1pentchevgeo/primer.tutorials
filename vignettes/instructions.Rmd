---
title: "Instructions for Writing Tutorials"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::knitr}
  %\VignetteIndexEntry{Instructions for Writing Tutorials}
  %\usepackage[UTF-8]{inputenc}
---

```{r not-setup, include=FALSE}
library(tidyverse)
library(knitr)
```

<!-- Explain that templates need to go after setup code chunk. -->

<!-- Make sure that you have ### after Section title. -->

*There are no questions here. There are only instructions!*

## Introduction

We are building the shallowest possible learning curve. Almost every student should be able to answer almost every Exercise, albeit perhaps with the help of the Hint. There are no hard questions. In fact, there really aren't *questions* at all. Instead, there are *instructions*. Do this. Then do that. Next do this other thing.

Assume that you are giving the student a private lesson. You ask them a question. They give you an answer. What would you say next to them? What do you want to teach them, given that context?

There are 100,000 bits of R knowledge which we might provide to students: tips, tricks, cool packages, fun websites, et cetera. We don't have time to mention all of them! The art of teaching is to, first, decide which 1,000 of the bits is most important to mention and, second, figure out the best time to mention them. Tutorials are a key location for doing that mentioning. Which bits do we mention and where do we mention them?

We are building a "pit of success." Generally, students don't do the assigned reading, at least in a large class. But, they will complete required work. They will do the tutorials. Our promise: If you complete the tutorials, you will become a data scientist. There is simply no way not to.

There will often be several tutorials for a given the chapter. The first few will be matched very closely to the structure of the chapter. Someday, we will [put those exercises directly](https://github.com/tinystats/teacups-giraffes-and-statistics) into the *Primer* itself, so keeping the two in sync makes sense. Extra tutorials have more freedom. They are designed to give more practice, reinforcing the material in the chapter, but with a bit of freedom for adding complications.

Tutorials should take about 1 to 2 hours. Depending on the question difficulty, that might be around 100 to 200 or so questions.

## Set Up

To make additions to **primer.tutorials**, follow the [set up guide](https://ppbds.github.io/primer/set-up-for-working-on-the-primer.html) to fork/download a copy of [PPBDS/primer.tutorials](https://github.com/PPBDS/primer.tutorials). Press "Install and Restart" from the "Build" tab to ensure that you have the latest copy installed. (You should not do `remotes::install_github("PPBDS/primer.tutorials")` since that gets the version from Github. You want the version from your computer so that you get any changes you make.) 

Keep in mind that there are (at least) two versions of **primer.tutorials** installed on your machine. In my case, we have

```{bash, eval = FALSE}
> /Library/Frameworks/R.framework/Versions/4.1/Resources/library
```

and


```{bash, eval = FALSE}
> /Users/davidkane/Desktop/projects/primer.tutorials/renv/library/R-4.1/x86_64-apple-darwin17.0/primer.tutorials
```

The first is the default location for packages. This is where things go unless you do something special. The second is installed in the *renv* directory which you created. When you are working in your primer.tutorials project, as you generally will, the renv version is what you will be using.


Tutorials themselves live in `inst/tutorials`. Each directory name is a combination of prefix numbers (which indicate the week/chapter which a tutorial is associated with) and a name. Everything is lower case with dashes instead of spaces. Within each directory is a `tutorial.Rmd` file and, sometimes, other material. The prefix number determines the order in which tutorials appear in the Tutorial pane.

To create a new tutorial, use File -> New File -> R Markdown. Choose "From Template" option and then select "Primer Tutorial." The "Technical Details" vignette provides an overview of the default material in the template. Change the `title`, `id`, and `description` parts of the YAML header. The title may include spaces. The `id` should be exactly the same as the `title`, but all in lower case and with spaces replaced with dashes. One sentence is enough for the description.

The `id` value is important. It should be the same as the directory in which the tutorial is located, but with the leading numbers removed. It is used for the name of the answer file which students save at the end of the tutorial. 

The beginning of every tutorial are the *Code Copying*and the *Information* info-section code chunks which requires providing your name and email. The tutorial is then divided into different *Sections* that you see as side panels. Within these sections, there are a series of *Exercises* which can include writing code or writing text. At the end of the tutorial, there is a *Download answers* section download-answers code chunk that provides students with instructions on how to download a copy of their answers. 

The 3 mandatory sections (copy-code-chunk, info-section, download-answers) are [imported](https://community.rstudio.com/t/include-custom-code-chunks-from-separate-files/109216) into each tutorial. Note that the setup code chunk must come before all of them.

The actual Rmd of these sections are saved in the `inst/child_documents` folder.



### Sections

Tutorials are divided into *Sections* that are seen on the side panel. To create these sections, we include a double hash (##) before the text for it to show up as a side panel. This is also called the Section Title.  Use sentence case. Directly below the Section title, put three hashes. This ensures that students will see the introductory text before they see the first Exercise.

Each Section begins with a sentence or two about what this group of Exercises is trying to accomplish. Then add a triple hash `###` to cause the tutorial to pause (with the "Continue" button) before it goes to the first Exercise. Example from the Data-API tutorial:

````markdown
## Interacting with Sites with `GET()`
###

In order to get data from an API, we use the **httr** package. The package is designed to imitate standard HTTP in R. Read more about HTTP [here](https://www.jmarshall.com/easy/http/).

###

### Exercise 1
````

### Exercises

Each Section is composed of a series of numbered Exercises. To create the exercise headers, you use three hashes. Make sure you number your exercises -- `### Exercise 1`, `### Exercise 2` and so on. This makes it easy for students to refer to a specific location when they have a question. Example:

````markdown
### Exercise 3

```{r the-terminal-ex-3, exercise = TRUE}

```
````

The code chunk name should begin with the name of the section followed by the appropriate Exercise number. (Note that we are working on a way to automatically create/update code chunk names for the entire document.) You must set `exercise = TRUE`. You must include at least one empty line in the code chunk, otherwise you will get a hard-to-diagnose error.

Any Exercise which requires the copying of code from the prior Exercise should place the Copy Code button below the Exercise code chunk by using:

````markdown
<button onclick = "transfer_code(this)">Copy previous code</button>
````

This will only work if all the special Javascript code is at the top of the Rmd.


### Hints

Tutorials should be so easy that 95% of the students can answer 95% of the questions easily, given that they have the *Primer* open as they work. One way to ensure that is to add a Hint to almost every coding question.

Hints must always have the same code chunk name as the exercise chunk for which they are the hint, with a "-hint" added at the end. So, if an exercise code chunk is named "ex-1", then the hint associated with that exercise is named "ex-1-hint". A second hint for that same question would be named "ex-1-hint-2", and so on. Note, however, that if you have a second (or third) hint, you must change the code chunk name for the first hint to end with `hint-1`. If you only have one hint, no number is necessary.

When you create a hint, always use `eval = FALSE` within the parentheses in the code chunk. This is because hints will often include "..." and other symbols which do not run as correct R code. So, we need to tell R not to run it or an error will occur during R CMD check. Example:

````markdown
`r ''````{r ex-1-hint-good, eval=FALSE}
This is an example hint. Normally sentences like these 
would cause an error in R because it is not proper code. 
However, since we include eval = FALSE in the r-chunk, 
R ignores all potential errors!
```
````

You need to wrap the text in a long hint by hand, inserting the carriage returns yourself. R will not wrap the text automatically.

Often, hints look like this

````markdown
`r ''````{r ex-1-hint, eval = FALSE}
... %>% 
  filter(year = ...) %>% 
  ...(flights)
```
````

The ... indicate places where the student needs to insert some code, a value or a function name. The code in hints should be formatted correctly.

In the current version of **learnr**, students can not see the first hint after clicking through to the next hint. So, make sure the last hint is the one you most want them to have access to, i.e., the one which provides the key information. If students can see the last hint, they should have no reason to consult any earlier hints. 

Hints are [only allowed](https://community.rstudio.com/t/hints-in-written-questions/108184) for coding questions, not for text or process questions. However, we can use this trick to add hints to those questions: simply add a `<div>` tag with an id attribute that marks it as hint for your exercise. Like this:

````markdown
`r ''`<div id="filter-hint">
**Hint:** You may want to use the dplyr `filter` function.
</div>
````


### Flow

Each Section begins with a few sentences which explain what this collection of exercises will teach us. Or it can "drop" some knowledge. But anything more than two sentences is much too much. Students won't read it. This portion is followed by with a triple hash on its own line. 

```{r, eval = FALSE}
###
```

This creates a "Continue" button  which students will have to click before they get to see the first exercise. This increases the odds (we hope!) that students will actually read the Section introduction.

Each Exercise should have a "flow" which requires that students hit the "Continue" button at least twice, and potentially more often. 

* Each Exercise begins with a sentence or two of knowledge and/or the question itself. If the length of the text is longer than one or two lines on the knitted Rmd, then do not show the exercise code chunk in the same part. Instead, the introduction is followed by the triple hashes, thereby creating the Continue button. If the length of the text is short enough that students are willing to read it (at most 2 lines), you can include the code chunk in the same part.

* Then follows the exercise code chunk, along with any hint code chunks --- and there should almost always be a hint or two. This grouping of code chunks are also followed by the triple hash. We want students to pause after they have run their code submissions.

* There should be a copy code button in between the exercise code chunk and the hints. This is absolutely required in cases in which it would be used, as when this Exercise builds on code from the previous Exercise. A Copy Code button is not necessary outside of this situation, but it also does not hurt anything.

* The last part of the Exercise is another knowledge drop. Again, this can't be more than a sentence or two. But it should be more substantive than a simple "Good job." Drop some knowledge! Use it. Of the 1,000 items which we want to mention, which one belongs here because it connects to the question/answer which students have just completed.

We have provided an "Add New Exercise Skeleton" to the Addins menu. Give it a try! It inserts the skeleton for the next Exercise, featuring all these component parts. It even takes a guess at the correct Exercise number. Highly recommended.








## Question types

There are three main types of questions. First, we have normal *coding* questions. Students write code and press the Run Code button. Second, we have *text* questions which require students to write prose. Third, we have *process* questions in which students are instructed to do something like connect to Github or edit an Rmd. We confirm that the students have completed these questions by having them issue a command like `list.files()` and then copy/pasting the result. (We use the same questions types for written and process questions.)

### Coding questions

We covered much of this above. Maybe re-arrange the material? The most common type of coding questions involve the step-by-step process of building a pipe, the final output of which is a nice looking graphic.

You want to first show the graphic that you will create by the end. You show it once at the start of the group and once before the last exercise, as a reminder of what the graphic should look like so users do not need to scroll all the way back up. 

You should put the code for the graph in the code chunk at the start of the section. Save the code to an object. The name of the object should have a _p suffix, where the "p" stands for "plot." This way, you only have to put the object name in the code chunk at the end of the section rather than copying the code.

You then build up the graphic, line by line, over the series of exercises, providing hints along the way. Along the way, it is fine to have a hint which reports: "This is what your code should look like now." That allows a student who is confused to catch. But don't do that too often since it will cause students to just look ahead to get the right answer.

#### Code answers

Good questions generate results when the student presses Run Code. Ideally, they press run code, see their results, hit Continue, and then see our answer to the same question. They can then confirm for themselves, immediately, that they got the right answer.

It is not always necessary to show our answers even though doing so is helpful to students worrying that they are off track. It is also unwise to just dump a whole pipe onto the screen, even if that is the "right" answer. Too much clutter!

Perhaps the best approach is to write "You should see that the value of height in row 1 is 23." This allows the students know that they are on the right track. Never hard-code a number. Use R to inline calculate it, even though this can be a bother.

### Text questions

Text questions look like the below. The actual question should be written above the code chunk. As always, the code chunk must have a name. Replace the `6` with the number of rows you want the answer box to have.

````markdown
### Exercise 2

Write about four sentences explaining, in your own words, the meaning of the motto "No causation without manipulation."

```{r, eval = FALSE}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 6))
```
````

(Of course, you need an R code chunk, with chunk name, in which to place this code.)

After a tripple hash, you should provide an excellent answer to any text question. We want to allow students to check for themselves that they got, more or less, the correct answer. We worry a bit that students, knowing that we always give the right answer, will start to cheat, always looking ahead for the answer and then using it. But, they know that copying/pasting our anwers will get them in trouble, so they have no choice but to, at least, put into their own words.

### Process questions

We want to give students plenty of practice with tasks like forking/cloning repos, committing files, editing Rmd files and so on. It can be difficult, however, to confirm that students have actually followed our instructions. The easiest way to confirm that they have done so is to issue commands which look at the filesystem and the files which live there. `list.files()` and `readLines()` are the key tools.

### RStudio setting questions

In many settings, it is natural for a set up question to have three parts. First, run a line of code that reports on the value of something. Example:


```{r, eval = FALSE}
rstudioapi::readRStudioPreference(name = "load_workspace", default = "Code failed.")
```

This will return TRUE, which is the default value. 

Second, change the setting. This generally won't return anything.


```{r, eval = FALSE}
rstudioapi::writeRStudioPreference(name = "load_workspace", value = FALSE)
```


See how the first was "read" and the second was "write"? Then, the third and final step is to confirm that the change worked by re-running the first code again.

```{r, eval = FALSE}
rstudioapi::readRStudioPreference(name = "load_workspace", default = "Code failed.")
```

And finish with a sentence that tells the student to notice that the value has changed and that it is now correct. (Of course, we "monitor" that by making them copy/paste this last command and its return from the Console into the tutorial.)

### Later tutorials in later chapters 

The first tutorial for each of the later chapters is easy. Just do more or less exactly what the chapter does. Recall that, one day, we expect to incorporate those questions directly into the chapter itself. So, the more that it just forces students to type in the same commands as in the chapter, the better. But, for the most part, the chapters are not that long! There is only about one tutorial worth of material.

What do we do for the other 5 or so tutorials for each chapter? Good question! Honestly, I am not sure. Here are some ideas:

* The second tutorial could be very similar to the first -- and, therefore, to the chapter. Just use a different variable(s) and/or a different tibble, but answer the same sorts of questions in the same way.

* Don't be repetitive in the written questions. It is fine, in the first tutorial for each chapter, to ask students to write a definition of the Preceptor Table. Indeed, we should always have that question in each first tutorial. But, we don't want that question in each of the 5 tutorials for a single chapter.

* Use written questions which do require different answers depending in the data/variable used. We can't resuse "Define a Preceptor Table" because that question has the same answer every time. Consider a different question:

> Write a paragraph which explores reasons why we should **not** consider the Preceptor Table and our data set as being drawn from the same population?

That is a good question, not least because it needs a different answer for each data science problem we confront. Another good example:

> Write a paragraph explaining why, even though the data is not a random sample, we may still consider it to be "respsentative" enough to move forward?

Again, this requires a different answer for each new tibble.

* We don't usually (ever?) ask questions about the four Cardinal Virtues directly. They are simply a pedagogical device we use to help students organize their work. But we do ask written questions about the key concepts (population, representativeness, validity) in each and every tutorial. These are difficult concepts with no "right" answers. We need to wrestle with them every week.

* A tutorial after the first might do a very similar exercise but with three differences. First, it can go faster, given that students have already seen the basics fairly slowly in the first tutorial. Second, it can add some complexity, make the modeling problem just a little more difficult than the basic case. Third, it can add some new magic. Perhaps it grabs data using a new package instead of just using another boring data set from **primer.data**. Perhaps it creates a nicer plot with some geoms we have not used before. 

* I will distribute the problem sets we used last semester. Turning them into tutorials might work well. But always remember that tutorials are easy, while problem sets are hard. So, we need to split up a big problem set question into 15 exercises and then walk the students slowly (and with hints) through those 10 exercises.

* Maybe there are easy ways, in tutorial 2 or 3, to take the problem we solved in tutorial 1 and have it loosen the assumption that the data we have is representative of the population. This is a nice assumption to loosen since it is never true. I am not sure how one would do this . . .

* If the main example is the chapter is one which uses a linear model, then tutorial 2 could use a logistic model and then tutorial 3 could use the third kind of model (which we have not chosen yet). Similarly, if the chapter (and first tutorial) does a predictive mode, then tutorial 3 should do a causal model.

* The last tutorial might, in some sense, try to set the stage for the next chapter, provide a teaser for what we are learning next.

* Another type of tutorial is one which uses fake data which has been manipulated to violate the assumptions which students are making. Show them Preceptor's Posterior and compare it to their own.



### Tips


Each coding exercise should always spit out something. Interactivity is good! Students should always look at what their code is spitting out. There are some situations in which students need to make assignments and which, because of this, will result in no output when the Run Code button is pressed. But:

* Do this as little as possible. Why not just make a pipe?

* When you do this, you will need to create the permanent object yourself because student work in an Exercise chunk has no lasting effects. Doing so is annoying and error prone.

* You can have the student not only do the assignment but also, as part of this same exercise, print out the object. This works well.


Prevent quotes from turning into curly quotes by writing `"nnet"` (with backticks around it) instead of "nnet". You never want curly quotes in something which might be copy/pasted to the prompt.  

Follow our Code Style Guide, especially spaces around operators like " = ". Use only one command per line in pipes and graphics, with proper indentation. Indent plotting commands after ggplot().


Do not create an object in one question and then assume that it will be available in subsequent questions. It won't be! Each question is independent of every other question. They live in separate R instances. The two exceptions to this is, first, code in the "setup" chunk for a question will be run and anything created will be available, but just in that question. Second (and this seems buggy and unreliable!) objects created in the initial setup chunk for the entire tutorial are available in all later questions, just the way that library() commands executed there do not need to be executed again. 

**Just putting code in a random R code chunk does not guarantee that that object will be available elsewhere, although it sometimes is!** Lesson is that, if you have an object you need just once, then create it in a setup chunk for that question. If you have an object you will need in multiple questions, create it in the setup chunk at the top of the lesson. TW thinks that you can use random R code chunks to do things, **but you must give those code chunks a name**.


The exercise code chunk should not have zero lines. It can be blank, but it must have at least one empty line.

Code chunks for questions must be named. Don't worry about the naming/numbering, as long as the code chunks don't have duplicate names.

Do not provide official **learnr** answers. There is no need to grade what the students submit. You may sometimes provide answers in a comment outside the code chunk, as a service to others authors working on the tutorial. Use your best judgment.


## Inputs

### Using data

Use built-in data sets in constructing tutorial questions, or use data sets which you create yourself in the tutorial. Note that several packages from the **tidyverse** have built in data, although it is worth making sure that they are tibbles rather than data frames. To see all the data sets in the Tidyverse, type `library(tidyverse)` first.  Then, you can look at these with --- `data()` --- and then looking for data sets associated with **tidyverse** packages. You can also use data sets from **primer.data**.

### Permanent objects

Permanent objects should be avoided, if possible. The problem is that each Exercise code chunk is its own "world." It knows nothing of any actions taken in previous code chunks, except for any setup code chunk you create just for that Exercise or for the initial setup code chunk for the whole tutorial. 

But what about regular code chunks which are neither Exercise code chunks nor setup chunks. Do objects created there persist? Maybe! Sometimes!

No aspect of the tutorials has given us more trouble than permanent objects. In particular, it sometimes seems like things will work with Run Document but not with Run Tutorial. Since students always do the latter, we need to test that way as well.

For now, only create permanent objects in the initial setup code chunk at the top of the Rmd.

### Using images

To add images to a tutorial, first make a directory called `images` in the folder that contains the `tutorial.Rmd`. Store all images for that tutorial there. Then, use the function `include_graphics()` to add the image into the document. Include this code in its own setup chunk, in the place where you want the image to appear in the tutorial. 

````
```{r example}
include_graphics("images/example.png")
```
````

`include_graphics()` is part of the `knitr` package, so you need `library(knitr)` in the setup code chunk. 

If the directory is not named `images` or is not within the same directory as the Rmd, the document will knit but the image [will not appear](https://rstudio.github.io/learnr/#external_resources).  

### Using files

There are two ways we can use files which we are certain are under our control. Both approaches involve first placing that file in `inst/www`. This ensures that it never disappears from the web. You may want to do that first, submit a PR, and then, once it is quickly accepted, the file will be available on Github for you to use in the tutorial.

The first approach is to write code which uses the url to the file in our Github repo. The second approach is to copy the file from the installed package to the workspace for a specific Exercise. (There is no way to make the file available for all Exercises in a tutorial.)

Consider this code from the Data A Tutorial for an example of the second approach.

````markdown
### Exercise 1

`r ''````{r ex-1-setup}
file.copy(system.file("www/test_1.csv", 
                      package = "primer.tutorials"), ".")
```
````

This ensures that the `test_1.csv` file will be available in the ex-1 exercise. (Note that the use of setup requires that the code chunk name have the same name as the exercise code chunk but with the "setup" suffix.)


### Check tutorial functionality 

#### Simple test

The simplest way to test the Rmd which you are working on is with:

```{r, eval = FALSE}
rmarkdown::render("inst/tutorials/02-terminal/tutorial.Rmd")
```

This assumes that you are located in the main directory of **primer.tutorials**, as you normally would be. I am not sure if this will catch all potential errors, but it will catch many issues, and it is very quick. Replace `02-terminal` with the appropriate directory.

#### Test before submitting a PR

Once you are done writing your tutorial, you need to make sure it works before you submit a pull request.

1. Click "Install and Restart" from the Build tab. Then, hit "Start Tutorial" in the Tutorial tab. This mimics the experience that users will have. This will catch some common errors, like having two code chunks with the same name. (I am not sure if this does more or less than the simple test above.)

2. Do a full test, which means running R CMD check. Go to the top right window of RStudio. Click the Build pane and hit the "Check" button (with the green check mark). You will then see a bunch of code and tests running. Make sure it says "OK" next to “testthat”. You should always run this before submitting a pull request.

#### What to do if R CMD check fails

1. Read the error message at the bottom of the Build pane. You want to see "R CMD check succeeded." If not, there is a problem. The error message will often provide a clue as to where in your code the error occurred.

2. If that error message is not detailed enough, go to the `primer.tutorials.rcheck` folder, which should be located in the same directory as `primer.tutorials`. This is a folder created by the R CMD check process, and it will be automatically deleted if the check process succeeds. If the process fails, the `primer.tutorials.rcheck` folder stays around so that you can examine it. The key file in there is `testthat.Rout.fail`, which should be in the `tests` directory. It has more details.

The most common source of errors is something wrong with the hint code chunks, which are not evaluated when you just Run Document. Make sure the `eval = FALSE` is set in the code chunk for all hints. Check also to see if you included the Information and Submission lines. 

#### Difficult bugs

* Note that R CMD check does not seem to catch cases in which you library() a package in a tutorial but that package is not in DESCRIPTION. But such a discrepancy will cause an error on Github Actions because, there, you only have access to packages that have been installed as part of that test.

* Be careful of the way that Github is sloppy in how it deals with capitalization changes, especially when you change the name of a file. For example, you might first commit a file named `Rproj.png`. Later, you decide to change all file names for images to all lower case. So, you change the name of the file to `rproj.png`. Commit and push. Everything is great, right? No! Even if Github shows you the new file name it might still have that file as `Rproj.png` internally. This will cause errors when your run your checks on Github: 

> Error: Cannot find the file(s): "images/rproj.png"

But the file is there! You can see it! The tests work on your local machine. The easiest solution is to delete the file (and commit that change). Only after it is gone can you then put it back. 

#### Default material

The first question (Information) should ask students to give us their name and email. (This way, when we generate a file with the student's responses, their name/email is included in that file). 

The last question (Download answers) provides instructions for downloading answers.

R CMD check will test that all tutorials have these sections exactly as they are in the Primer Tutorial template. So, use the template. If either the "Introduction" or "Download answers" sections are missing, R CMD check will return something like "From test-components.R. Submission (or Information) lines missing from file".





