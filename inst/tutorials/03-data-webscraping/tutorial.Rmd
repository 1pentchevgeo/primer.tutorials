---
title: "Data Webscraping"
tutorial:
  id: "data-webscraping"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: "Chapter 3: Data -- Webscraping"
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(rvest)
library(png)
library(grid)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 
```


## Information
###

```{r information}
quiz(caption = "",
  question_text(
    "Name:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL),
  question_text(
    "Email:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL))
```

## HTML

```{r setup-html-section, echo=FALSE}
raw_html1 <- "<html>Hello World</html>"

raw_html2 <- "<html>
<table>
  <tr>
    <td>
      Hello World
    </td>
  </tr>
</table>
</html>"

raw_html3 <- "<html>
<table>
  <tr>
    <td>
      Hello World
    </td>
    <td>
      foo
    </td>
    <td>
      bar
    </td>
  </tr>
</table>
</html>"

td_tags <- minimal_html(raw_html3) %>% html_elements("td")
```

HTML, or "HyperText Markup Language" is a markup language that is used to display webpages on browsers. You might have seen html files as a result of knitting Rmd files.

###

### Exercise 1

In this tutorial, you will use the `rvest` package to read the HTML of websites and extract data. First, import the `rvest` package.

You may need to install the `rvest` package in RStudio's console if the code box below outputs an error. If so, use `install.packages("rvest")` in console.

```{r html1, exercise=TRUE}

```

``` {r html1-hint-1, eval=FALSE}
library(...)
```

###

`rvest` is part of the `tidyverse`, a collection of packages, but it is not part of the core `tidyverse` package so you have to load it in separately. https://rvest.tidyverse.org/ is its official website.

### Exercise 2

HTML uses many nested layers of different tags to organize structure.

For example:

An html file like this:
```{.html}
<html>
Hello World
</html>
```

creates the following:
<br>

<html style="background-color:gray">
Hello World
</html>

<br>

Tags are represented like `<...></...>`, similar to parentheses. You will see different kinds of tags and what they can do. This example uses the html tag `<html>`, which is the main tag that includes the entire webpage.

###

You will be parsing the following html structure:
```{.html}
<html>
<p>
Hello World
</p>
</html>
```

Assign the provided html code into the variable `raw_html1`.

```{r html2, exercise=TRUE}
"<html><p>Hello World</p></html>"

```

```{r html2-hint-1, eval=FALSE}
raw_html1 <- "<html>Hello World</html>"

```

###

You can now use the `raw_html1` variable

### Exercise 3

Using the function `minimal_html()`, load in `raw_html1`. This function takes the raw html text and creates an object to easily access information.

Later, you will read html directly from websites.


```{r html3, exercise=TRUE}

```

```{r html3-hint-1, eval=FALSE}
minimal_html(...)
```

```{r html3-hint-2, eval=FALSE}
minimal_html(raw_html1)
```


###

`rvest` reads html data and constructs a nested list-like object to represent the usual nested structure of html.

The output is similar to the output of a list.

### Exercise 4

Copy/paste your code from above and extend it using ` %>% `. Use the function `html_element()` to select the first `<p>` tag inside the structure.

`html_element()` takes a string that shows the type of a tag.
For example, `<p>` can be found with `"p"`.

```{r html4, exercise=TRUE}

```

```{r html4-hint-1, eval=FALSE}
minimal_html(...) %>% html_element(...)
```

```{r html4-hint-2, eval=FALSE}
minimal_html(...) %>% html_element("p")
```

###

You can see it returned an `{html_node}` object that is the tag `<p>`

### Exercise 5

Copy/paste your pipe from above and extend it. Use the function `html_text2()`, which prints the text inside a tag.

```{r html5, exercise=TRUE}

```

```{r html5-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("p") %>% html_text2()
```

###

The output should be "Hello World". Now you can access the inside of a tag.

### Exercise 6

Usually, html tag structures are nested like the following:

```{.html}
<html>
<table>
  <tr>
    <td>
      Hello World
    </td>
  </tr>
</table>
</html>
```

###

You will parse the above html

Assign the provided html to a variable named `raw_html2`

```{r html6, exercise=TRUE}
"<html>
<table>
  <tr>
    <td>
      Hello World
    </td>
  </tr>
</table>
</html>"
```

```{r html6-hint-1, eval=FALSE}
raw_html2 <- "..."
```

###

Now you have access to `raw_html2`

### Exercise 7

Start a pipe using the function `minimal_html()` and `raw_html2` as its argument

```{r html7, exercise=TRUE}

```

```{r html7-hint-1, eval=FALSE}
minimal_html(...)
```

###

Now you can search for elements inside the html.

### Exercise 8

Copy/paste your code from above and extend it with ` %>% `. Using `html_element()`, find the first `<table>` tag.

Remember that `html_element()` takes the type of tag you want to search for as an argument.

So to search for `<table>`, you can use `"table"` as an argument.

```{r html8, exercise=TRUE}

```

```{r html8-hint-1, eval=FALSE}
minimal_html(...) %>% html_element(...)
```

```{r html8-hint-2, eval=FALSE}
minimal_html(...) %>% html_element("table")
```

###

The output like last time returns an `{html_node}` object that has the `<table>` tag.

The lines after the `<table>` show the elements inside `<table>`.

### Exercise 9

Copy/paste your pipe from above and extend it. Use the function `html_element()` again to search for `<td>` tag inside the `<table>` tag.

```{r html9, exercise=TRUE}

```

```{r html9-hint-1, eval=FALSE}
minimal_html(...) %>% html_element(...) %>% html_element(...)
```

```{r html9-hint-2, eval=FALSE}
minimal_html(...) %>% html_element("table") %>% html_element("td")
```

###

By extending your pipe from the resulting `<table>` tag, you are limiting your searches and functions to only inside the `<table>` tag. You can see from the results that you have selected the `<td>` tag that is inside the `<table>` tag.

### Exercise 10

Copy/paste your pipe from above and extend it. Use the `html_text2()` function to view the text inside the `<td>` tag.

```{r html10, exercise=TRUE}

```

```{r html10-hint-1, eval=FALSE}
minimal_html(...) %>% html_element(...) %>% html_element(...) %>% html_text2()
```

###

Now you can navigate deep into the nested structure of html.

### Exercise 11

Usually there are many elements with the same tag on a webpage, which means selecting only the first element with a tag using `html_element()` will not work.

###

Consider the following html:
```{.html}
<html>
<table>
  <tr>
    <td>
      Hello World
    </td>
    <td>
      foo
    </td>
    <td>
      bar
    </td>
  </tr>
</table>
</html>
```

There are 3 separate `<td>` tags. If you want to select the middle `<td>` with `foo` as its text, it will be hard for you to use `html_element()`.

###

You will parse the above html

Assign the provided html to a variable named `raw_html3`

```{r html11, exercise=TRUE}
"<html>
<table>
  <tr>
    <td>
      Hello World
    </td>
    <td>
      foo
    </td>
    <td>
      bar
    </td>
  </tr>
</table>
</html>"
```

```{r html11-hint-1, eval=FALSE}
raw_html3 <- "..."
```

###

You now have access to `raw_html3`

### Exercise 12

Start a pipe using `minimal_html()` and `raw_html3` as its argument.

```{r html12, exercise=TRUE}

```

```{r html12-hint-1, eval=FALSE}
minimal_html(...)
```

###

You can now search through `raw_html3` for elements.

### Exercise 13

Copy/paste your code from above and extend it with ` %>% `. You will use the function `html_elements()` (Note that it is `elements`, not `element`) to find all `<td>` tags.

`html_elements()` takes the same argument as `html_element()`. Use the tag type of `<td>`, which is `"td"`.

```{r html13, exercise=TRUE}

```

```{r html13-hint-1, eval=FALSE}
minimal_html(...) %>% html_elements("...")
```

```{r html13-hint-2, eval=FALSE}
minimal_html(...) %>% html_elements("td")
```

###

`html_elements()` is very similar to `html_element()`, only that it returns all results compared to `html_element()` first result.

The output returns a `{xml_nodeset (3)}` object, which is basically a list, and then lists all the results.

### Exercise 14

Since the result is a list, you can navigate it exactly like how you would with a list.

###

Copy/paste your pipe from above and assign it to a variable called `td_tags`. You will use it in the next exercise.

```{r html14, exercise=TRUE}

```

```{r html14-hint-1, eval=FALSE}
td_tags <- minimal_html(...) %>% ...
```

###

You now have `td_tags`, which is essentially a list object.

### Exercise 15

Index `td_tags` and extract the second object using brackets.

```{r html15, exercise=TRUE}

```

```{r html15-hint-1, eval=FALSE}
td_tags[[...]]
```

###

Remember to use double brackets to extract an object from a list.

You have selected the second object in `td_tags`, which should print out an `{html_node}` object like you've seen before in earlier exercises.

### Exercise 16

Copy/paste your indexing code and pass it into `html_text2()` as an argument. This will extract the text of the `<td>` tag that you have selected.

```{r html16, exercise=TRUE}

```

```{r html16-hint-1, eval=FALSE}
html_text(td_tags[[...]])
```

###

Well done! This is the basic structure of HTML. It is tags inside tags inside tags.

Now you can navigate the nested structure of html, select  tags based on position and tag type, and extract the inner text of tags.

## CSS Selectors

###

```{r setup-css-section, echo=FALSE}
anchor <- '<a https://ppbds.github.io/primer/index.htm" id="abcd1234" class="hello hi">link to primer</a>'
```

CSS, or Cascading Style Sheets is a language that defines the style of webpages (colors, boxes, spacing, etc).

CSS uses different attributes of tags to find which tags should be formatted in which way.

###

Consider the following CSS code:
```{r, eval=FALSE, echo=TRUE}
p {
color: red
}
```

This code formats all the `<p>` tags red.

You can utilize this system to find the tags that you want.

### Exercise 1

A tag's attributes are shown like such in html:
``` {.html}

<a href="https://ppbds.github.io/primer/index.html" id="abcd1234" class="hello hi">
link to primer
</a>

```

In the above example, the `<a>` anchor tag has 3 different attributes:<br>
`href` which contains the destination link<br>
`id` which contains a unique id<br>
`class` which contains the classes that this tag is a part of.

###

Assign the html for the `<a>` tag into a variable named `anchor`

```{r css1, exercise=TRUE}
'<a https://ppbds.github.io/primer/index.htm" id="abcd1234" class="hello hi">link to primer</a>'

```

```{r css1-hint-1, eval=FALSE}
anchor <- '...'
```

###

You now have access to the `anchor` variable.

### Exercise 2

Start a pipe with `minimal_html()` and `anchor` as its argument.

```{r css2, exercise=TRUE}

```

```{r css2-hint-1, eval=FALSE}
minimal_html(...)
```

###

You have loaded the html and can now start to select elements inside.

### Exercise 3

You have been using `html_element()` to find elements with the type of tag (`<a>`, `<p>`, `<table>`, etc), but you can also select an element with CSS attributes.

###

``` {.html}

<a href="https://ppbds.github.io/primer/index.html" id="abcd1234" class="hello hi">
link to primer
</a>

```

Copy/paste your code from above and extend it with ` %>% `. Then use the function `html_element()`.

Select the `<a>` tag using its `id` attribute, `"abcd1234"`.

You specify that you are filtering by `id` in `html_element()` by using `"#id_name"`.

```{r css3, exercise=TRUE}

```

```{r css3-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("#abcd1234")
```

###

Since `id` is a unique identifier, every page should only have one tag that uses that `id`, which is helpful to select specific elements.

### Exercise 4

Copy/paste your pipe from above and extend it with the function `html_text2()`. This prints out the text inside the `<a>` tag that you have selected.

```{r css4, exercise=TRUE}

```

```{r css4-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("#abcd1234") %>% html_text2()
```

###

The output is the text inside, which is "link to primer"

### Exercise 5

Start a new pipe using `minimal_html()` and `anchor`.

```{r css5, exercise=TRUE}

```

```{r css5-hint-1, eval=FALSE}
minimal_html(...)
```

###

Now we will try to select using the `class` attribute instead of `id`.

### Exercise 6

``` {.html}

<a href="https://ppbds.github.io/primer/index.html" id="abcd1234" class="hello hi">
link to primer
</a>

```

Copy/paste your code from above and extend it with ` %>% `. Then use the function `html_element()`.

Select the `<a>` tag using its class attribute, `"hello"`. You specify that you are filtering by `class` in `html_element()` by preceding a class name with `"."`.

```{r css6, exercise=TRUE}

```

```{r css6-hint-1, eval=FALSE}
minimal_html(...) %>% html_element(".hello")
```

###

You will notice that the `<a>` tag's full class attribute is actually `"hello hi"`. This means that this `<a>` tag belongs to both the `hello` class and the `hi` class. (You can try selecting with `".hi"` instead of `".hello"`)

Classes are not unique to one tag, so usually there are multiple tags with the same class and tags with multiple classes.

### Exercise 7

Since there can be multiple tags with the same class, it is often safer to use the `html_elements()` to return all results, so you can better find the element you want.

###

Copy/paste your pipe from above and extend it with `html_text2()`. You can view the inner text of the `<a>` tag.

```{r css7, exercise=TRUE}

```

```{r css7-hint-1, eval=FALSE}
minimal_html(...) %>% html_element(".hello") %>% html_text2()
```

###

Now you can select with class and id as well as extract text from that element.

### Exercise 8

You can also filter by id, class, and type of tag at the same time by chaining them together.

Consider the following code:
```{r, eval=FALSE, echo=TRUE}

minimal_html(some_html) %>% html_element("p#id_name")

```

This code selects the first `<p>` tag with `"id_name"` as its `id`

###

Start a new pipe with `minimal_html()` and `anchor`, then extend it with ` %>% `. Use the `html_element()` function to select the anchor tag by specifying its tag type and `id`.

Remember that to select `id`, you have to precede the `id` value with a `#`.

The `<a>` tag's `id` is `"abcd1234"`

```{r css8, exercise=TRUE}

```

```{r css8-hint-1, eval=FALSE}
minimal_html(anchor) %>% html_element("a#abcd1234")
```

###

Though it may seem redundant to be even more specific, there are always weird website html that could break the constraint of having only one unique `id`.

Adding this extra layer of specificity just makes your selection more accurate.

### Exercise 9

Copy/paste your pipe from above and extend it. Use the function `html_text2()` to see the inner text of the tag.

```{r css9, exercise=TRUE}

```

```{r css9-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("a#abcd1234") %>% html_text2()
```

###

You can now select by chaining tag type and id value, then extract the text.

### Exercise 10

Consider the following code:
```{r, eval=FALSE, echo=TRUE}

minimal_html(some_html) %>% html_element("p.class_name")

```

This code selects the first `<p>` tag with `"class_name"` as one of its `class`

###

Start a new pipe with `minimal_html()` and `anchor`, then extend it with ` %>% `. Use the `html_element()` function to select the anchor tag by specifying its tag type and `class`.

Remember that to select `class`, you have to precede the `class` value with a `.`.

The `<a>` tag's `class` attribute is `"hello hi"`

```{r css10, exercise=TRUE}

```

```{r css10-hint-1, eval=FALSE}
minimal_html(anchor) %>% html_element("a.hello")

# or 

minimal_html(anchor) %>% html_element("a.hi")
```

###

Now you can select using class and tag type at the same time.

### Exercise 11

Copy/paste your pipe from above and extend it. Use the function `html_text2()` to see the inner text of the tag.

```{r css11, exercise=TRUE}

```

```{r css11-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("a.hello") %>% html_text2()

# or
minimal_html(...) %>% html_element("a.hi") %>% html_text2()
```

###

Well done.

### Exercise 12

Finally, consider the following code:
```{r, eval=FALSE, echo=TRUE}

minimal_html(some_html) %>% html_element("p#id_name.class_name")

```

This code selects the first `<p>` tag with both `"id_name"` as its `id` AND `"class_name"` as one of its `class`

###

Start a new pipe with `minimal_html()` and `anchor`.

```{r css12, exercise=TRUE}

```

### Exercise 13

Copy/paste your code from above and extend it with ` %>% `. Use the `html_element()` function to select the anchor tag by specifying its tag type, `id`, and `class`.

html of `<a>` tag:
``` {.html}

<a href="https://ppbds.github.io/primer/index.html" id="abcd1234" class="hello hi">
link to primer
</a>

```

Remember:
To select `class`, you have to precede the `class` value with a `.`.

To select `id`, you have to precede the `id` value with a `#`.

```{r css13, exercise=TRUE}

```

```{r css13-hint-1, eval=FALSE}
minimal_html(anchor) %>% html_element("a#abcd1234.hello")

# or 

minimal_html(anchor) %>% html_element("a#abcd1234.hi")

```

###

Now you can select using id, class, and tag type at the same time.

### Exercise 14

Copy/paste your pipe from above and extend it. Use the function `html_text2()` to see the inner text of the tag.

```{r css14, exercise=TRUE}

```

```{r css14-hint-1, eval=FALSE}
minimal_html(anchor) %>% html_element("a#abcd1234.hello") %>% html_text2()

# or 

minimal_html(anchor) %>% html_element("a#abcd1234.hi")%>% html_text2()
```

###

Well done.

### Exercise 15

Up until now, you have been extracting only the inner text of tags. However, there are times when the data you want is in the tag's attribute.

Consider again the following tag:
``` {.html}

<a href="https://ppbds.github.io/primer/index.html" id="abcd1234" class="hello hi">
link to primer
</a>

```

The `href` attribute can be helpful if you are collecting urls.

###

Start a new pipe with `minimal_html()` and `anchor`.

```{r css15, exercise=TRUE}

```

```{r css15-hint-1, eval=FALSE}
minimal_html(...)
```

###

You now loaded in the html in `anchor`.

### Exercise 16

Copy/paste your pipe from above and extend it with ` %>% `. Use the function `html_element()` to select the `<a>` tag with both its tag type and `id` attribute, `"abcd1234"`.

```{r css16, exercise=TRUE}

```

```{r css16-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("#...")
```

```{r css16-hint-2, eval=FALSE}
minimal_html(...) %>% html_element("#abcd1234")
```

###

You have now selected the `<a>` tag.

### Exercise 17

Copy/paste your pipe from above and extend it with `html_attr()`.
This function takes as an argument the name of the attribute that you want to select in quotes. Select the `href` attribute of the `<a>` tag.

```{r css17, exercise=TRUE}

```

```{r css17-hint-1, eval=FALSE}
minimal_html(...) %>% html_element("#abcd1234") %>% html_attr("...")
```

```{r css17-hint-2, eval=FALSE}
minimal_html(...) %>% html_element("#abcd1234") %>% html_attr("href")
```

###

Now you can also extract data from the attributes of tags. You can try `"class"` or `"id"` since both are also attributes.

Nice work!

## Wikipedia Tables

###

```{r setup-wiki-section, echo=FALSE}
wiki_url <- "https://en.wikipedia.org/w/index.php?title=%22,%22Gun_violence_in_the_United_States_by_state%22,%22&direction=prev&oldid=810166167"

raw_data <- read_html(wiki_url) %>%
  html_element("#mw-content-text") %>%
  html_element("table.wikitable") %>%
  html_table()
```

Now you will try your hand in scraping data from a Wikipedia page about gun violence in the United States by state and plotting it.

###

<a href="https://en.wikipedia.org/w/index.php?title=%22,%22Gun_violence_in_the_United_States_by_state%22,%22&direction=prev&oldid=810166167">Link to webpage</a>

Check out the page. You will be scraping the table data.

### Exercise 1

Assign the url provided below to a variable called `wiki_url`.

```{r wiki1, exercise=TRUE}
"https://en.wikipedia.org/w/index.php?title=%22,%22Gun_violence_in_the_United_States_by_state%22,%22&direction=prev&oldid=810166167"

```

```{r wiki1-hint-1, eval=FALSE}
wiki_url <- "..."
```

###

Now you have access to the variable `wiki_url`.

### Exercise 2

Use the function `read_html()` and `wiki_url` as argument to read the html of the Wikipedia webpage.

`read_html()` takes a link and reads the html of that webpage.

```{r wiki2, exercise=TRUE}

```

```{r wiki2-hint-1, eval=FALSE}
read_html(...)
```

```{r wiki2-hint-2, eval=FALSE}
read_html(wiki_url)
```

###

You now loaded the html of the webpage into R, similar to how you did with `minimal_html()` in earlier sections.

You can begin to select elements in the page.

### Exercise 3

The following html is the section that contains the main content of the page:
```{.html}
<div id="mw-content-text" class="mw-body-content mw-content-ltr" lang="en" dir="ltr">...</div>
```

###

Copy/paste your pipe from above and extend it with ` %>% `. Select the main content element with the function `html_element()` using its `id` attribute.

```{r wiki3, exercise=TRUE}

```

```{r wiki3-hint-1, eval=FALSE}
read_html(...) %>% html_element("#...")
```

```{r wiki3-hint-2, eval=FALSE}
read_html(...) %>% html_element("#mw-content-text")
```

###

You have selected the main content section of the page.

You can see that it has a lot of different attributes and items inside the tag. It can be overwhelming at times but if you focus on the parts you know like `id` or `class`, you will be fine.

### Exercise 4

The following is the tag for the table inside the section selected in the previous exercise:
```{.html}
<table class="wikitable sortable jquery-tablesorter">...</table>
```

###

Copy/paste your pipe from above and extend it with the function `html_element()`. Select the table with both its tag type AND one of its `class`.

```{r wiki4, exercise=TRUE}

```

```{r wiki4-hint-1, eval=FALSE}
read_html(...) %>% html_element("#mw-content-text") %>% html_element("tag_type.class_name")
```

```{r wiki4-hint-2, eval=FALSE}
read_html(...) %>% html_element("#mw-content-text") %>% html_element("table.wikitable")
```

###

Now you have access to the data table.

### Exercise 5

The `rvest` package provides a great table-parsing function, `html_table()`, that allows you to load in web-scraped tables easily.

###

Copy/paste your pipe from above and extend it with the function `html_table()`. This allows you to load in data in the table in the form of a dataframe.

```{r wiki5, exercise=TRUE}

```

```{r wiki5-hint-1, eval=FALSE}
read_html(...) %>% html_element("#...") %>% html_element("tag_type.class_name") %>% html_table()
```

###

Nice work!

Now you have a dataframe web-scraped directly from Wikipedia.

### Exercise 6

Copy/paste your pipe from above and assign it to a variable named `raw_data`.

```{r wiki6, exercise=TRUE}

```

###

Now you saved the Wikipedia data into a variable, so you do not have to repeatedly web-scrape the page everytime you re-run the pipe.

### Exercise 7

Let's create the following plot:
```{r make-wiki_graph, echo=FALSE}
clean_data <- raw_data %>% rename(
  population='Population (total inhabitants) (2015) [1]',
  total_deaths=`Murders and Nonnegligent\nManslaughter(total deaths) (2015) [2]`,
  death_rate=`Murder and Nonnegligent\nManslaughter Rate(per 100,000 inhabitants) (2015)`) %>%
  select(population, death_rate) %>%
  mutate(population=as.integer(gsub(",", "", population))) %>%
  mutate(pop_tile=ntile(population, 20)) %>%
  group_by(pop_tile) %>%
  summarize(sum_rate=sum(death_rate), num_states=n()) %>%
  mutate(avg_rate=sum_rate/num_states) %>%
  mutate(percent_rate=avg_rate/sum(avg_rate))
wiki_graph <- clean_data %>%
  ggplot(aes(x=pop_tile, y=percent_rate)) + 
  geom_col() + 
  geom_smooth(method="loess", formula=y~x, se=FALSE) +
  scale_x_continuous(breaks=1:20) +
  scale_y_continuous(
    labels=scales::percent_format(accuracy=1)) +
  theme_classic() + 
  labs(title="Distribution of US Death Rate by Guns in Quantile of Population in 2015",
       subtitle="Death rate of less populated states fluctuate more than states with a denser population",
       x="Quantile by Population (least to most)",
       y="Percent of Average Death Rate",
       caption="Wikipedia: Gun Violence in the United States (2017)")

wiki_graph
```

###

Run `glimpse()` on `raw_data` to understand the structure of the data.

```{r wiki7, exercise=TRUE}

```

```{r wiki7-hint-1, eval=FALSE}
glimpse(...)
```

###

`Population (total inhabitants) (2015) [1]` and `Murders and Nonnegligent\nManslaughter(total deaths) (2015) [2]` should be integer columns but are character columns because of the commas in the numbers.

More often than not, data that's web-scraped are unclean. Therefore, before doing any plotting, you must clean the data.

### Exercise 8

Start a pipe with `raw_data`.

First, let's rename the columns to make referencing them easier.

Using the `rename()` function, rename all the columns as such: <br><br>
`"Population (total inhabitants) (2015) [1]"` to `population`<br><br>
`"Murders and Nonnegligent\nManslaughter(total deaths) (2015) [2]"` to `total_deaths`<br><br>
`"Murder and Nonnegligent\nManslaughter Rate(per 100,000 inhabitants) (2015)"` to `death_rate`<br><br>

Remember that `rename()` is similar to `mutate()` in the way it is used:<br>
`rename(new_column_name=old_column_name, new_col2=old_col2, ...)`

```{r wiki8, exercise=TRUE}

```

```{r wiki8-hint-1, eval=FALSE}
raw_data %>% rename(...=..., ...=...)
```

```{r wiki8-hint-2, eval=FALSE}
raw_data %>% rename(population=`Population (total inhabitants) (2015) [1]`, total_deaths=...)
```

###

Now it is easier for you to refer to the columns.

### Exercise 9

Copy/paste your pipe and extend it. Use the function `select()` to select only the columns you need, which are `population` and `death_rate`.

```{r wiki9, exercise=TRUE}

```

```{r wiki9-hint-1, eval=FALSE}
... %>% select(...)
```

###

The only column that is unclean now is `population`.

### Exercise 10

Copy/paste your pipe and extend it.

Remove all the commas in `population` using `gsub()`, which is just `sub()` except it replaces all matches instead of the first.

Then use `mutate()` to store the results in the same column.

`gsub()` takes a `pattern` to match, string to `replace` the patterns with, and the values to be changed.

```{r wiki10, exercise=TRUE}

```

```{r wiki10-hint-1, eval=FALSE}
... %>% mutate(population=gsub(...))
```

```{r wiki10-hint-2, eval=FALSE}
... %>% mutate(population=gsub(",", "", population))
```

###

As you can see from the result, the population column no longer has commas in it.

### Exercise 11

Now you can change the `population` column's type from character to integer.

###

Copy/paste your pipe from above and extend it. Use the `as.integer()` function to change `population` to an integer column.

Then use `mutate()` to store the results in the same column.

```{r wiki11, exercise=TRUE}

```

```{r wiki11-hint-1, eval=FALSE}
... %>% mutate(population=as.integer(...))
```

```{r wiki11-hint-2, eval=FALSE}
... %>% mutate(population=as.integer(population))
```

###

As you can see from the output, right below the column name, `population` is now a `<int>`, or integer column.

### Exercise 12

Now you can begin dividing the data into quantiles.

###

Copy/paste your pipe from above and extend it. Use the `ntile()` function to split `population` into 20 quantiles.

Then use `mutate()` to store the results in a new column called `pop_tile`.

Remember that `ntile()` takes as arguments the data that it is splitting and the number of groups to split into.

```{r wiki12, exercise=TRUE}

```

```{r wiki12-hint-1, eval=FALSE}
... %>% mutate(pop_tile=ntile(...))
```

```{r wiki12-hint-2, eval=FALSE}
... %>% mutate(pop_tile=ntile(population, 20))
```

###

You can see the new column in the output, `pop_tile`, which has values between 1 and 20. This refers to which quantile that row is in.

### Exercise 13

Copy/paste your pipe from above and extend it. Group your data by `pop_tile`.

```{r wiki13, exercise=TRUE}

```

```{r wiki13-hint-1, eval=FALSE}
.. %>% group_by(...)
```

###

The output may look like a normal table, but the grouping has already been done.

### Exercise 14

Copy/paste your pipe from above and extend it. Summarize your data with 2 columns:
Number of States in quantile as `num_states`
Sum of death rate in quantile as `sum_rate`

```{r wiki14, exercise=TRUE}

```

```{r wiki14-hint-1, eval=FALSE}
... %>% summarize(...)
```

```{r wiki14-hint-2, eval=FALSE}
... %>% summarize(num_states=n(), sum_rate=sum(...))
```

###

The resulting tibble is your summarized data. You can see from the `num_states` column that some of the quantiles have more states than others.

### Exercise 15

In order to counter the imbalanced number of states, you will average the `sum_rate` of each quantile.

###

Copy/paste your pipe from above and extend it. Create a new column using `mutate()` called `avg_rate`, which is the average rate in quantile per state.

```{r wiki15, exercise=TRUE}

```

```{r wiki15-hint-1, eval=FALSE}
... %>% mutate(avg_rate=...)
```

```{r wiki15-hint-2, eval=FALSE}
... %>% mutate(avg_rate=sum_rate/num_states)
```

###

Now you can see the new column called `avg_rate`.

### Exercise 16

Now let's calculate the percentage of each quantile's average rate over all quantiles' average rates. 

###

Copy/paste your pipe from above and extend it. Create a new column using `mutate()` called `percent_rate`, which is the percentage of each quantile's average rate over the sum of all quantiles'.

```{r wiki16, exercise=TRUE}

```

```{r wiki16-hint-1, eval=FALSE}
... %>% mutate(percent_rate=.../sum(...))
```

```{r wiki16-hint-2, eval=FALSE}
... %>% mutate(percent_rate=avg_rate/sum(avg_rate))
```

###

Now you finally have everything you need for plotting!

### Exercise 17

Copy/paste your pipe from above and assign it to a variabled named `clean_data`.

```{r wiki17, exercise=TRUE}

```

###

Now you have access to `clean_data`.

### Exercise 18

Start a plot with `ggplot()`. Use `clean_data` as data and map `pop_tile` to the x-axis and `percent_rate` to the y-axis. Add a `geom_col()` to create a bar graph.

```{r wiki18, exercise=TRUE}

```

```{r wiki18-hint-1, eval=FALSE}
ggplot(data=..., mapping=aes(...)) + geom_col()
```

###

You can now see the distribution.

### Exercise 19

Copy/paste you code from above and add another layer with `geom_smooth()`. Use `"loess"` as its method, `y~x` as its formula, and set `se` to `FALSE`. This adds a kind of trend line that visualizes the data better.

```{r wiki19, exercise=TRUE}

```

```{r wiki19-hint-1, eval=FALSE}
... + geom_smooth(method=..., formula=..., se=...)
```

###

The data visualization itself is basically done, but you'll notice that the x-axis isn't chunked properly and the y-axis should be in percentage.

### Exercise 20

Copy/paste your code from above and add another layer using the function `scale_x_continuous()`. Assign to its `breaks` argument `1:20` to break the x-axis into 1 through 20.

```{r wiki20, exercise=TRUE}

```

```{r wiki20-hint-1, eval=FALSE}
... %>% scale_x_continuous(breaks=...)
```

```{r wiki20-hint-2, eval=FALSE}
... %>% scale_x_continuous(breaks=1:20)
```

###

Now the x-axis makes sense.

### Exercise 21

Next let's format the y-axis into percentages.

###

Copy/paste your code from above and add another layer with `scale_y_continuous()`. Assign to its `labels` argument `scales::percent_format(accuracy=1)`, which changes the y-axis into percentage format.

```{r wiki21, exercise=TRUE}

```

```{r wiki21-hint-1, eval=FALSE}
... %>% scale_y_continuous(labels=...)
```

```{r wiki21-hint-2, eval=FALSE}
... %>% scale_y_continuous(labels=scales::percent_format(accuracy=1))
```

###

Now both the axes are labeled accordingly.

### Exercise 22

Copy/paste your code from above and add a `theme_classic()` layer to the plot. Then add the appropriate labels with `labs()`.

```{r wiki22, exercise=TRUE}

```

```{r wiki22-hint-1, eval=FALSE}
... %>% labs(title="...",
             subtitle="...",
             x="...",
             y="...",
             caption="...")
```

Reminder: this is how your plot should look like.
```{r show-wiki_graph, echo=FALSE}
wiki_graph
```

###

Well done!

### (Optional) Exercise 23

A part of web-scraping that is not covered here is actually finding the element you want to scrape from the website's html.

If you'd like to, you can read how to access a website's html and identify the location of elements below for different browsers:

<a href="https://developer.chrome.com/docs/devtools/open/">Chrome</a>

<a href="https://developer.mozilla.org/en-US/docs/Tools/Page_Inspector/How_to/Open_the_Inspector">Firefox</a>

<a href="https://stackoverflow.com/questions/40234993/how-to-inspect-element-using-safari-browser">Safari</a>

## Open Secrets Table

###

```{r setup-open-section, echo=FALSE}
web_url <- "https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/2020"

raw_data <- read_html(web_url) %>% 
  html_element("table.DataTable-Partial") %>% 
  html_table()


```

For more practice, you will be scraping data from opensecrets.org. The data is about the amount and sources of money donated to Democratic and Republican parties in 2020.

<a href="https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/2020">Link to page</a>

Check out the page. You will be reading the table underneath the map.

### Exercise 1

Assign the url provided below to a variable named `web_url`.

```{r open1, exercise=TRUE}
"https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/2020"

```

```{r open1-hint-1, eval=FALSE}
web_url <- "..."
```

###

Now you have access to the variable `web_url`.

### Exercise 2

Use the function `read_html()` and `web_url` as argument to read the html of the webpage.

```{r open2, exercise=TRUE}

```

```{r open2-hint-1, eval=FALSE}
read_html(...)
```

###

You now loaded the html of the webpage into R, similar to how you did with `minimal_html()` in earlier sections.

You can begin to select elements in the page.

### Exercise 3

The following html shows the `table` tag's attributes:
```{.html}
<table class="DataTable-Partial dataTable no-footer" data-title="Foreign Connected PACs, 2019-2020" data-paging="true" data-page-length="25">...</table>
```

###

Copy/paste your pipe from above and extend it with ` %>% `. Select the table using the function `html_element()` with both the tag type and its first `class` attribute.

```{r open3, exercise=TRUE}

```

```{r open3-hint-1, eval=FALSE}
read_html(...) %>% html_element("tag.class_name")
```

```{r open3-hint-2, eval=FALSE}
read_html(...) %>% html_element("table.DataTable-Partial")
```

###

You have selected the desired table.


### Exercise 4

The `rvest` package provides a great table-parsing function, `html_table()`, that allows you to load in web-scraped tables easily.

###

Copy/paste your pipe from above and extend it with the function `html_table()`. This allows you to load in data in the table in the form of a dataframe.

```{r open4, exercise=TRUE}

```

```{r open4-hint-1, eval=FALSE}
... %>% html_table()
```

###

Nice work!

Now you have a dataframe web-scraped directly from OpenSecrets.

### Exercise 5

Copy/paste your pipe from above and assign it to a variable named `raw_data`.

```{r open5, exercise=TRUE}

```

###

Now you saved the table data into `raw_data`, so you do not have to repeatedly web-scrape the page everytime you re-run the pipe.

### Exercise 6

Let's make the following graph:

```{r make-open_graph, echo=FALSE}
open_graph <- raw_data %>% rename(pac_name="PAC Name (Affiliate)", country_and_parent="Country of Origin/Parent Company") %>% select(country_and_parent, Dems, Repubs, Total) %>% mutate(Dems=gsub("[^0-9]", "", Dems)) %>% mutate(Dems=as.integer(Dems)) %>% mutate(Repubs=gsub("[^0-9]", "", Repubs)) %>% mutate(Repubs=as.integer(Repubs)) %>% mutate(Total=gsub("[^0-9]", "", Total)) %>% mutate(Total=as.integer(Total)) %>% mutate(country_and_parent=gsub("/(.*)", "", country_and_parent)) %>% rename(country=country_and_parent) %>% group_by(country) %>% summarize(dem_sum=sum(Dems), repub_sum=sum(Repubs), total=sum(Total), .groups="drop") %>% arrange(desc(total)) %>% mutate(country=as.factor(country)) %>% slice(1:10)  %>% pivot_longer(cols=c(dem_sum, repub_sum), names_to="party", values_to="amount") %>% ggplot(mapping=aes(x=reorder(country, amount, sum), y=amount/100000, fill=party)) + geom_col(position="dodge") + theme_classic() + theme(axis.text.x=element_text(angle = -90, hjust=0)) + scale_fill_manual(values=c("blue", "red"), labels=c("Democrat", "Republican")) + labs(title="Top 10 Countries with the Highest Total Company Donations\nto US Political Parties in 2020", subtitle="There seems to be more donations towards\nthe republican party than to the democratic party", x="Country", y="Donations (in $100,000)", fill="Party")
open_graph
```

###

Use `glimpse()` to check `raw_data`.

```{r open6, exercise=TRUE}

```

```{r open6-hint-1, eval=FALSE}
glimpse(...)
```

###

Somethings to take note: <br>
the columns `Total`, `Dems`, `Repubs` are character columns instead of integer. <br>
the names of the first 2 columns are quite long.

### Exercise 7

Let's first rename the 2 columns.

###

Start a pipe with `raw_data` and extend it with ` %>% `. Use the `rename()` function, which takes arguments similar to `mutate()`, and rename:
`"PAC Name (Affiliate)"` to `pac_name`
`"Country of Origin/Parent Company"` to `country_and_parent`.

```{r open7, exercise=TRUE}

```

```{r open7-hint-1, eval=FALSE}
raw_data %>% rename(col1=old_col1, col2=old_col2, ...)
```

###

Now `pac_name` and `country_and_parent` are more easily accessible.

### Exercise 8

Copy/paste your pipe from above and extend it with the function `select()`. You will use that function to select the columns you need, which are `country_and_parent`, `Dems`, `Repubs`, and `Total`.

```{r open8, exercise=TRUE}

```

```{r open8-hint-1, eval=FALSE}
... %>% select(...)
```

```{r open8-hint-2, eval=FALSE}
... %>% select(country_and_parent, ...)
```

###

Now you only have the columns you need left.

### Exercise 9

Now let's remove the `$` and `,` from `Repubs`, `Dems`, and `Total`.

###

Copy/paste your pipe from above and extend it with the function `mutate()`. You will use `gsub()` to delete all the `$` and `,` in all 3 columns.

Use the pattern `"[^0-9]"`, which selects everything in a string that is NOT a digit, and replace these selections with an empty string, essentially deleting them.

Remember that `gsub()` takes as arguments a `pattern` to detect with, a string to `replace` with, and the column to act on.

Assign the new column to the same column name for all 3 columns.

```{r open9, exercise=TRUE}

```

```{r open9-hint-1, eval=FALSE}
... %>% mutate(col1=gsub(...), col2=gsub(...), ...)
```

```{r open9-hint-2, eval=FALSE}
... %>% mutate(Dems=gsub("[^0-9]", "", Dems), Repubs=gsub(...), Total=gsub(...))
```

###

Now you can see that `Dems`, `Repubs`, and `Total` are all purely digits.

### Exercise 10

Let's change the `Dems`, `Repubs`, and `Total` columns into integer columns.

###

Copy/paste your pipe from above and extend it using the function `mutate()`. Change the columns with `as.integer()` and assign the new columns to the same name.

```{r open10, exercise=TRUE}

```

```{r open10-hint-1, eval=FALSE}
... %>% mutate(col1=as.integer(col1), col2=as.integer(col2), ...)
```

###

Now if you look below the column names for `Dems`, `Repubs`, and `Total`, they are registered as `<int>` which means integer columns.

### Exercise 11

Since you are plotting by country, there is no need to keep the parent company in the `country_and_parent` column, so let's change that.

###

Copy/paste your pipe from above and extend it with `mutate()`. Use the `gsub()` function to delete everything after the `/` and then assign the new column to the column name, `country`.

You can use the pattern `"/(.*)"`, which selects everything after the `/`, and then replace it with `""` to delete it.

```{r open11, exercise=TRUE}

```

```{r open11-hint-1, eval=FALSE}
... %>% mutate(country=gsub(...))
```

```{r open11-hint-2, eval=FALSE}
... %>% mutate(country=gsub("/(.*)", "", country_and_parent))
```

###

Now you have a new column called `country` that is only the country source of donation.

### Exercise 12

In order to find out more about each country's statistics, you need to group the data by `country`.

###

Copy/paste your pipe from above and extend it with `group_by()`. Group the data by `country`.

```{r open12, exercise=TRUE}

```

```{r open12-hint-1, eval=FALSE}
... %>% group_by(...)
```

###

It might not seem like there's a change but, if there is no error, the data has already been grouped by `country`.

### Exercise 13

After grouping, you should `summarize` the data

###

Copy/paste your pipe from above and extend it with `summarize()`. You will create 3 separate values:<br>
`dem_sum` as the `sum()` of donations for democrats<br>
`repub_sum` as the `sum()` of donations for republicans <br>
`total` as the `sum()` of total donations<br><br>

Remember to `"drop"` the groups after summarizing.

```{r open13, exercise=TRUE}

```

```{r open13-hint-1, eval=FALSE}
... %>% summarize(..., .groups="drop")
```

```{r open13-hint-2, eval=FALSE}
... %>% summarize(dem_sum=sum(...), repub_sum=sum(...), total=sum(...), .groups="drop")
```

###

Now you have a small table showing each country's total donation to each party as well as the total donations.

### Exercise 14




<!-- This should be a 60 to 90 minutes worth of exercises devoted to webscraping, with a big focus on the rvest package. Also need to teach some CSS and Selector Gadget. Resources: -->

<!-- If students would just read this paper closely and try out the associated commands -->

<!-- https://github.com/mdogucu/web-scrape -->

<!-- then a tutorial would not be necessary. But they won't! And, even if most of them would, teachers still need a way of knowing that they did. Hence, tutorials. Can we write something that, in essence, forces students to type out everything in that article and understand what it is doing? That is the goal! -->

<!-- https://github.com/rstudio-education/dsbox/tree/master/inst/tutorials/05-moneyinpolitics -->
<!-- https://minecr.shinyapps.io/dsbox-05-moneyinpolitics/ -->


<!-- There is no need to reinvest the wheel. All this code is CC0, so we can just copy/paste it, including the links to images which appear on the web. But how do we ensure that students do things? What questions do we ask? -->

<!-- https://rvest.tidyverse.org/ -->
<!-- https://github.com/tidyverse/rvest/blob/master/vignettes/rvest.Rmd -->
<!-- https://github.com/tidyverse/rvest/blob/master/vignettes/articles/selectorgadget.Rmd -->

<!-- Maybe the tutorial starts the same way as this chapter, with a concrete example of what we are trying to do. Note that we just used this prose in our chapter. Again, it is all CC0. -->

<!-- https://rafalab.github.io/dsbook/web-scraping.html -->

<!-- Reminders: -->

<!-- 1) You can put a raw html (or any other kind of file) in inst/www and then be certain is available on Github. You may want to submit a PR which does that, and then, when I accept it, you can write code which accesses it directly. Example url: -->

<!-- https://raw.githubusercontent.com/PPBDS/primer.tutorials/master/inst/www/delim_1.txt -->

<!-- 2) This tutorial is just about raw webscraping, not about working with APIs or JSON. Other tutorials handle that. -->

<!-- 3) Key structure is to, first, begin with sections which highlights the key issues and key commands. Then, have 5 or so concrete examples, each of which works with an html file which we have a permanent copy of. (But how do we show how that file looks in a browser? I am confused about that.) Nothing wrong with all the examples being from Wikipedia and referencing specific versions, even if they are old. -->

<!-- 4) Plan is to write this tutorial and then, afterwards, update the Chapter to be consistent with it. -->

<!-- 5) Use html_text2(). Background: https://www.tidyverse.org/blog/2021/03/rvest-1-0-0/ -->


 

## Submit

```{r context = "setup"}
submission_ui
```

```{r context = "server"}
submission_server()
```
