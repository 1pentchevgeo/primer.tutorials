---
title: "Probability B"
tutorial:
  id: "probability-b"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 5 tutorial Part B"
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)

x <- tibble(p = rep(seq(0, 1, 0.1), 1000)) %>%
  mutate(heads = map_int(p, ~ rbinom(n = 1, size = 20, p = .)))


knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 
```


## Information
###

```{r information}
quiz(caption = "",
  question_text(
    "Name:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL),
  question_text(
    "Email:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL))
```


## N Models 
###

Let's create the following *empirical distribution* for possible simulations for $\rho_h$. In other words, we will create a joint distribution of models which might be true and of data which our experiment might generate. 

```{r}
x <- tibble(p = rep(seq(0, 1, 0.1), 1000)) %>%
  mutate(heads = map_int(p, ~ rbinom(n = 1, size = 20, p = .)))

emp_p <- x %>%
  ggplot(aes(y = p, x = heads)) +
    geom_jitter(alpha = 0.1) +
    labs(title = "Empirical Distribution of Number of Heads",
         subtitle = expression(paste("Based on simulations with various values of ", rho[h])),
         x = "Number of Heads out of 20 Tosses",
         y = expression(rho[h])) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  theme_classic()

emp_p
```

### Exercise 1

Use `tibble()` with one variable `p` set to the function `rep()`. Within `rep()` use the argument `seq()` that takes on the values 0, 1, and .1.

```{r nm-1, exercise = TRUE}

```

```{r nm-1-hint-1, eval = FALSE}
tibble(...= rep(c(..., ..., ...)))
```

### Exercise 2

Great. Let's have our code run 1000 times. Add the argument 1000 to `rep()`

```{r nm-2, exercise = TRUE}

```

```{r nm-2-hint-1, eval = FALSE}
 tibble(p = rep(c(0, 1, .1), ...))
```

### Exercise 3

Pipe your code to the function `mutate()` to create the variable `heads`. Set `heads` to the function `map_int()`. The first argument to `map_int()` should be `p`. The second argument should be an `rbinom()` where `n` is set to 1, `size` is set to 20, and `p` is set to `.`.

```{r nm-3, exercise = TRUE}

```

```{r nm-3-hint-1, eval = FALSE}
 ... %>% 
  mutate(p = map_int(..., ~ rbinom(...,
                                   ..., 
                                   ...)))
```

### Exercise 4

Copy/paste your code above. Assign your code to an object named `x`.

```{r nm-4, exercise = TRUE}

```

```{r nm-4-hint-1, eval = FALSE}
x <- ...
```

### Exercise 5

Pipe `x` to `ggplot()`. Map `heads` to the x-axis and `p` to the y-axis. Also add the layer `geom_jitter()`. 

```{r nm-5, exercise = TRUE}

```

```{r nm-5-hint-1, eval = FALSE}
x %>% 
  ggplot(aes(x = ..., y = ...)) +
    geom_jitter()
```

### Exercise 6

Set `alpha` to .1 within `geom_jitter()`. 

```{r nm-6, exercise = TRUE}

```

```{r nm-6-hint-1, eval = FALSE}
... +
  geom_jitter(...)
```

### Exercise 7

Now use `scale_y_continuous()`. Set `breaks` to the function `seq()` that contains the values 0, 1, and .1.

```{r nm-7, exercise = TRUE}

```

```{r nm-7-hint-1, eval = FALSE}
... + 
  scale_y_continuous(breaks = seq(..., ..., ...)
```

### Exercise 8

Finally, use `labs()` to add the appropriate title, subtitle, and axis labels. Also add the layer `theme_classic()`.

```{r nm-8, exercise = TRUE}

```

Reminder: This is what your plot should look like.

```{r}
emp_p
```

###

Let's create the following *unnormalized conditional distribution*. This is essentially a slice of the joint distribution we previously created. 

```{r}
unnorm_p <- x %>% 
  filter(heads == 8) %>% 
  ggplot(aes(p)) +
    geom_bar() +
    labs(title = expression(paste("Values of ", rho[h], " Associated with 8 Heads")),
         x = expression(paste("Assumed value of ", rho[h], " in simulation")),
         y = "Count") +
  theme_classic()

unnorm_p
```

### Exercise 9

`filter()` `x` for where `heads` is equal to 8.

```{r nm-9, exercise = TRUE}

```

```{r nm-9-hint-1, eval = FALSE}
x %>% 
  filter(heads == ...)
```

### Exercise 10

Pipe your code above to `ggplot()`. Map `p` to the x-axis.  Also add the layer `geom_bar()`.

```{r nm-10, exercise = TRUE}

```

```{r nm-10-hint-1, eval = FALSE}
... %>% 
  ggplot(aes(...)) +
  geom_histogram()
```

### Exercise 11

Finally, use `labs()` to add the title "Values of P(h) with 8 Heads". Then label your x-axis "Assumed value of P(h) in simulation". Also add the layer `theme_classic()`.

```{r nm-11, exercise = TRUE}

```

Reminder: This is what your plot should look like.

```{r}
unnorm_p
```


###

Let's create the following *normalized conditional distribution*. In other words, we are normalizing the graph we just created.

```{r}
norm_p <- x %>% 
  filter(heads == 8) %>% 
  ggplot(aes(x = p)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 50) + 
    labs(title = expression(paste("Posterior Probability Distribution of ", rho[h])),
         x = expression(paste("Possible values for ", rho[h])),
         y = "Probability") +
    scale_x_continuous(breaks = seq(0.2, 0.7, by = 0.1)) +
    scale_y_continuous(labels = 
                        scales::percent_format(accuracy = 1)) +
  theme_classic()

norm_p

```

### Exercise 12

We begin our code the same way we began our code for the *unnormalized conditional distribution*. We have provided the code for you below. To begin, add the layer `geom_histogram()` and set `bins` to 50.


```{r nm-12, exercise = TRUE}
x %>% 
  filter(heads == 8) %>% 
  ggplot(aes(x = p))
```

```{r nm-12-hint-1, eval = FALSE}
... +
  geom_histogram(...)
```

### Exercise 13

Within `geom_histogram()`, use `after_stat()` . Inside `after_stat()`, use `aes()` with the argument `y = count/sum(count)` to put percents on the y-axis.

```{r nm-13, exercise = TRUE}

```

```{r nm-13-hint-1, eval = FALSE}

```

### Exercise 14

Now use `scale_x_continuous()`. Set `breaks` to `seq()` that contains the values 0.2 and 0.7. Also set `by` to 0.1 within `seq()`.

```{r nm-14, exercise = TRUE}

```

```{r nm-14-hint-1, eval = FALSE}
... +
  scale_x_continuous(... = seq(..., ..., ...))
```

### Exercise 15

Now use `scale_y_continuous()` to put the y-axis in percent format. Within `scale_y_continuous()`, set `labels` to `scales::percent_format()`. Within `percent_format()` set `accuracy` to 1.

```{r nm-15, exercise = TRUE}

```

```{r nm-15-hint-1, eval = FALSE}
... + 
  scale_y_continuous(labels = scales::percent_format(...))
```


### Exercise 16

Finally, use `labs()` to add the title "Posterior Probability Distribution of P(h)". Then label your x-axis "Possibility values for P(h)" and y-axis "Probability". Also add the layer `theme_classic()`.


```{r nm-16, exercise = TRUE}

```

Reminder: This is what your plot should look like.

```{r}
norm_p
```


```{r nm-16-hint-1, eval = FALSE}

```




## Download answers

```{r context = "setup"}
submission_ui
```

```{r context = "server"}
submission_server()
```




