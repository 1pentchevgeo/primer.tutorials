---
title: "API"
tutorial:
  id: "data-api"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 3: Working with APIs"
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(httr)
library(WDI)
library(plotly)
library()
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

# Makes URL use simpler throughout the exercises. 

meso_url <- "https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"

my.response <- GET(url = meso_url) 
```


<!-- Do not even mention API keys in the initial Query section. Too confusing! Instead, have the second section, called "API Keys" walk through the concept. 

This second section would show an example of using a key we provide in a call to a the API. First question, run GET without API key. Get back this failure. Sad! Then run this command with API key. Get back data. Cool! Then run `usethis::edit_r_environ()` -->

<!-- BM: unsure how to implement edit_r_environ in a useful way -->

<!-- > denver <- GET(url = meso_url) -->
<!-- > denver -->
<!-- Response [https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/] -->
<!--   Date: 2021-05-22 14:28 -->
<!--   Status: 500 -->
<!--   Content-Type: text/plain; charset=UTF-8 -->
<!--   Size: 23 B -->

<!-- > class(denver) -->
<!-- [1] "response" -->
<!-- >  -->

## Information
###

```{r information}
quiz(caption = "",
  question_text(
    "Name:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL),
  question_text(
    "Email:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL))
```

## Queries
###

In order to get data from an API, we use the **httr** package.


### Exercise 1

Load the `httr` package.  

```{r library, exercise = T}

```

```{r library-hint, eval = FALSE}
Use the library(...) command. 
```

### 

We now have access to the `httr` package. 


### Exercise 2

Because the Iowa Environmental Mesonet doesn't require us to use a user-specific API key, we can use a base URL to send an HTTP request. 

###

Assign the url in your code to an an object named `meso_url`. 

```{r create_url, exercise = TRUE}
"https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"

```

```{r create_url-hint-1, eval = FALSE}
The URL should be a text string when being assigned to an object. 
```

```{r create_url-hint-2, eval = FALSE}
meso_url <- "https://..." 
```


###

<!-- In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. This is a simpler example of API use in which we don't need to protect a uniquely generated access key.  -->

You will now have access to this object throughout the rest of the tutorial. The **base URL** allows you to send a request and specify the subset of data you want. 


### Exercise 3

`GET()` is the key command in the **httr** package. It takes in the URL to the API and optionally a query to define the limits of the data accessed. 

###

Use `GET()` with the `url` argument set to `meso_url`. Assign the resulting object to `my.response`. In the second line, run `class()` on `my.response`.

```{r query-0, exercise = TRUE}

```

```{r query-0-hint, eval = FALSE}
my.response <- GET(url = ...)
```

```{r query-0-hint-2, eval = FALSE}
class(my.response)
```

###

Note that even without a query specification, the GET command appears to run but returns no data. You get an object of `class()` "response" because you are still communicating with the base url. 

### Exercise 4

Print out `my.response`. 

```{r query_01, exercise = TRUE}

```

```{r query_01-hint, eval = FALSE}
my.response
```

###

Note that the URL is still the base url, which indicates that there was no further query. We can confirm that by looking at the size of the response - 23 Bytes. THe `Status: 500` indicates that the query encountered an error. 


### Exercise 5

Within the function `GET()`, use `meso_url` to fill the `url` argument and then set the argument `query` equal to a `list()` of parameters: `station`, `data`, `year1`.  We want to know for station Denver (`"DEN"`) the temperature in degrees Fahrenheit (`"tpmf"`) starting in the year 2017. You still will not get data from this query. Assign this output to an object named `denver`. 

```{r query-1, exercise = TRUE}

```

```{r query-1-hint-1, eval = FALSE}
The abbreviation for temperature in Fahrenheit is "tmpf".
```

```{r query-1-hint-2, eval = FALSE}
... <- GET(url = ...,
           query = list(station = ...,
                        data = "tmpf",
                        year1 = ...))
```

### 

There are several different types of data to be had from this API, including the temperature in degrees celsius, which come with different `data` query arguments. 

### Exercise 6

This API requires a start and end date (Year, Month, and Day) to be supplied in order to return a request successfully. 

###

Copy and paste the code for `denver` from the previous exercise. Within `GET()`, you should add parameters to include the start, `year1` `month1` `day1`, and end point of your time frame, `year2` etc. We are interested in the daily records from 01/01/2017 to 12/31/2019. You should also specify the appropriate time zone for the station listed. The time zone for the Denver station is "America/Denver". 

```{r query2, exercise = TRUE}

```

```{r query2-hint-1, eval = FALSE}
All date parameters should be quoted numbers
i.e. "01" is January.
```

```{r query2-hint-2, eval = FALSE}

denver <- GET(url = meso_url,
                    query = list(station = "DEN",
                                 data = "tmpf",
                                 year1 = "2017",
                                 month1 = ...,
                                 day1 = ...,
                                 year2 = "2019",
                                 month2 = ...,
                                 day2 = ...,
                                 tz = ...))

```

<!-- Here we should probably keep assignment and have them call a denver programmed in the set_up chunk?  -->

### Exercise 7

Now we have data. Copy the code from the previous exercise. Remove thh assignment of the code's output to `denver` and run the code.  Note the size of the response - you should have ~7.98 MB of data. 

```{r query_resp1, exercise = TRUE}

```

```{r query_resp1-hint, eval = FALSE}
GET(url = meso_url,
    query = list(station = "DEN",
                 data = "tmpf",
                 year1 = "2017",
                 month1 = "01",
                 day1 = "01",
                 year2 = "2019",
                 month2 = "12",
                 day2 = "31",
                 tz = "America/Denver"))
```

###

Now that we have data, we need to format it in a user-friendly way. 
Note that a successful query will show a small amount of the data below the response in addition to the `Status: 200` completion code and an extended URL that reflects the items in the query. 

### Exercise 8

This API allows us to download the data in CSV format. 

###

Within the `list()` for `query`, set `format`  equal to `comma` (as in Comma Separated Variables). Then, to convert this data to a more familiar format, add the `content()` and `read_csv()` functions immediately following the `GET()` query to convert the gibberish from the query response into a tibble. 

```{r query-3, exercise = TRUE}

```

```{r query-3-hint, eval = FALSE}
GET(url = ...,
              query = list(...,
                           format = "comma")) %>% 
  content() %>% 
  read_csv(... , ...)

Make sure that you properly address NA values - see Primer for examples. 
```

### 

Recall that the `content()` call extracts the content from the response to the HTTP request sent by the `GET()` function and allows us to parse the content like a traditional CSV file. 

### Exercise 9

The many Ms is this dataset's way of representing missing values. Within `read_csv()`, use the `na` argument to change all occurrences of the lone character `"M"` to `NA`.Save this output as an object named 'denver'. 

```{r query-10, exercise = TRUE}
GET(url = ...,
              query = list(...,
                           format = "comma")) %>% 
  content() %>% 
  read_csv(... , ...)

Make sure that you properly address NA values - see Primer for examples. 
```

```{r query-10-hint, eval = FALSE}

```

### Exercise 10

Print out the `denver` object. 

```{r print_denver, exercise = TRUE}

```

###

You should see a normally formatted tibble, like we have dealt with in the last few weeks.

```{r get_denver_data}
denver <- GET(url = meso_url,
                    query = list(station = c("DEN"),
                                 data = "tmpf",
                                 year1 = "2017",
                                 month1 = "1",
                                 day1 = "1",
                                 year2 = "2019",
                                 month2 = "12",
                                 day2 = "31",
                                 tz = "America/Denver",
                                 format = "comma")) %>%
  content() %>% 
  read_csv(skip = 5, na = "M")
```

### Exercise 11

Let's use the data to make the following plot. 

```{r make_plot_1}
denver_p <- denver %>% 
  separate(col = valid,
           into = c("date", NA),
           sep = " ") %>%
  group_by(date) %>%
  summarise(avg_temp = mean(tmpf, na.rm = TRUE),
            .groups = "drop") %>% 
  ggplot(aes(y = avg_temp,
                  x = date)) +
  geom_point() + 
  scale_x_discrete(breaks = c("2017-06-01", "2018-06-01", "2019-06-01")) +
  labs(x = NULL,
       y = "Average Temp. F*",
       title = "Daily Avg. Temperature in Denver, CO",
       caption = "Source: Iowa Environmental Mesonet")

denver_p
```

Let's remove the timestamp from the given date variable and rename the remaining column "date". Within the function `separate()`, use the argument `col` to select which column's content you are separating, use the argument `into` to create a vector of the new column names, `"date"` and `NA`, and use the third argument to show by what character you are separating the data `" "`.  Save this as an object named `d1`

```{r plot-11, exercise = TRUE}

```

```{r plot-11-hint, eval = FALSE}

d1 <- denver %>% 
  separate(col = valid,
           into = c(..., NA),
           sep = " ")

```

###

The NA operator drops the second column from the separation - removing the need to select(-X) the unwanted data later. 

### Exercise 12

The date column has multiple rows for the same day. Continue your pipe and use `group_by()` and `summarize()` to calculate the daily average temperature in a new column named "avg_temp". 

```{r plot-2, exercise = TRUE}

```

```{r plot-2-hint-1, eval = FALSE}
Within the `mean()` function, set `na.rm` to TRUE to remove NA values from 
calculation. 
```

```{r plot-2-hint-2, eval = FALSE}

d1 <- denver %>% 
  separate(col = ...,
           into = c(..., NA),
           sep = ...) %>% 
  ... %>% 
  group_by(...) 
  summarise(avg_temp = ...,
            .groups = "drop")


Be careful with NA values!

```


###

Now, you will have access to the `d1` object. 

### Exercise 13

Now that we have the desired calculations, start a new pipe with `d1` and create a scatterplot that maps average daily temperature to the y-axis and the date to the x-axis. 

```{r plot-3, exercise = TRUE}

```

```{r plot-3-hint, eval = FALSE}
d1 %>% 
  ggplot(aes(x = ..., y = ...)) +
  geom_point()
  ...
```

### Exercise 14

There are so many labels for x-axis breaks that they are indistiguishable. Use `scale_x_discrete()` to set only three x axis breaks, `06-01-2017`, `06-01-2018`, `06-01-2019`.
```{r plot-4, exercise = TRUE}

```

```{r plot-4-hint, eval = FALSE}

d1 %>% ggplot(aes(y = ...,
                  x = ...)) +
  geom_point() + 
  scale_x_discrete(breaks = c(...)) 
```

### Exercise 15

Use `labs()` to set an appropriate title, subtitle, caption, axes labels, and captions.

```{r denver-15, exercise = TRUE}

```

Reminder: The graph should look like this

```{r show-denver-p}
denver_p
```


## API Keys

In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. The following are examples of examples of API use in which we don't need to protect a uniquely generated access key.

## Wikipedia Page Access
###

The **pageviews** package provides helper functions for accesses the API for the World Bank. You can learn more about the package [here](https://cran.rstudio.com/web/packages/pageviews/pageviews.pdf). 


```{r wb_setup}
supreme_views <- old_pageviews(project = "en.wikipedia",
                           article = "Supreme_Court_of_the_United_States",
                           platform = "all",
                           user_type = "all",
                           start = "2008012000",
                           end = "2016012000") 

supreme_plot <- supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("Date:", date, "\n"))) +
  geom_col() +
  labs(title = "Wikipedia Supreme Court Page During Pres. Obama's Tenure",
       x = "Date", 
       y = "Views", 
       caption = "Wikimedia Traffic Data API")

final <- ggplotly(supreme_plot, tooltip = "text")

final
```



### Exercise 1

On the first line, load the **pageviews** package. In this package, the functions `article_pageviews()` and `old_pageviews()` allow us to communicate with the Wikimedia API. 

```{r supreme-01, exercise = TRUE}

```

```{r supreme-01-hint, eval = FALSE}
library(pageviews)
```

###

`old_pageviews()` is for counts before 2016. They are not accurate as they did not omit the activity of web-crawlers and bots.

### Exercise 2

We will be looking at the wikipedia page views for the Supreme Court of the United States countries during President Obama's tenure, from January 20th 2008 to January 20th 2016.

###

Start a call with `old_pageviews()`. Set the `project` argument equal to `wikipedia.en` and the article to `Supreme_Court_of_the_United_States`. Set the start time and end time in the format: YYYYMMDDHH. Set hours to 00, they do not matter as the granularity is by default daily. Assign this to an object called `supreme_views`.

```{r supreme-02, exercise = TRUE}

```

```{r supreme-02-hint-1, eval = FALSE}
Use the WDIsearch() tool from the previous question if you are having 
difficulty locating the proper indicator. 
```

```{r supreme-02-hint-2, eval = FALSE}
old_pageviews(project = "en.wikipedia",
                           article = "Supreme_Court_of_the_United_States",
                           start = "2008012000",
                           end = "2016012000") 
```

###

Because this is a package designed to work with this API, we do not need to use a base url. Also, the output of the function is made into a tibble by default.

### Exercise 3

Start a new pipe with `supreme_views`. Use `ggplot()` and `geom_col()` to make a bar graph with `date` on the x-axis and `views()` on the y axis. 

```{r supreme-03, exercise = TRUE}

```

```{r supreme-03-hint, eval = FALSE}
supreme_views %>% 
  ggplot(aes(..., ,...)) +
  geom_col()
```

### Exercise 4

Use the `text` argument and the function `paste()` to create a label which you can use for plotly.

```{r supreme-04, exercise = TRUE}

```

```{r supreme-04-hint-1, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("...", ..., "\n"))) +
  geom_col()
```

```{r suoreme-04-hint-2, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("Date:", date, "\n"))) +
  geom_col()
```

###

### Exercise 5

Use `labs()` to set an appropriate title, caption, and axes labels

```{r supreme-05, exercise = TRUE}

```

### Exercise 6

Copy/paste your code. Assign the output of the pipe to an object called `supreme_plot`.

```{r supreme-06, exercise = TRUE}

```

### Exercise 7 

Use the function `ggplotly()` to add interactive labels to supreme_plot.

```{r supreme-07, exercise = TRUE}

```

```{r supreme-07-hint-1, eval = FALSE}
ggplotly(..., tooltip = "text")
```

```{r suoreme-07-hint-2, eval = FALSE}
ggplotly(..., tooltip = "text")
```


Reminder: you plot should look like this: 

```{r show-supreme-plot}
final
```

<!-- The remaining tasks to cover on this tutorial are to add more examples of API / API packages to reinforce the tools to find indicator codes and explore various open data offerings such that the tutorial takes 50-60 minutes. -->

## The World Bank
###

The **WDI** package provides helper functions with access to the API for the World Bank. You can learn more about the package [here](http://vincentarelbundock.github.io/WDI/). 


```{r wb_setup}
ratio <- WDI(
  country = "all",
  indicator = "BI.WAG.PRVS.FM.SM",
  start = 1990,
  end = 2020,
  language = "en")

ratio_p <- ratio %>%
  rename(ratio = BI.WAG.PRVS.FM.SM) %>%
  drop_na(ratio) %>%
  filter(country %in% c("Colombia", "El Salvador", "Honduras",
                        "Panama", "Philippines")) %>%
  ggplot(aes(x = year, y = ratio, color = country)) +
  geom_point() +
  geom_line(aes(group = iso2c)) +
  
  # debating the best way to show the y-axis - 100% is an even distribution, but
  # I don't want to mislead the unattentive reader
  
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Female to Male Private Sector Wage Ratio",
    subtitle = "Women tend to earn more than men in Honduras",
    y = "Female-to-Male Wage Ratio",
    caption = "Source: The World Bank via the WDI API package",
    x = NULL,
    
    # Dropping the legend title
    
    color = NULL)

ratio_p

```


### Exercise 1

The most complex part of this edition of an API call on the World Bank's data is the data indicator - the obscure name string that selects the type of information pulled. Thankfully - there are some handy functions from the **WDI** package we can use. 

###

On the first line, load the **WDI** package. On the subsequent line, use `WDIsearch()` to search indicator descriptions for "investment", and take a look at the first ten results.

```{r wdi-00, exercise = TRUE}

```

```{r wdi-00-hint, eval = FALSE}
library(WDI)
WDIsearch(...)[1:10,] 

# or

WDIsearch(...) %>% 
  head(...)
```

###

This works for an array of terms that the World Bank may have data about - feel free to explore! It is important to note the indicator of the data you wish to extract as it must be entered in your query. 

### Exercise 2

Will be looking at various countries and their private sector wage allocation between males and females, *as measured by the average group wage across business sectors* between 1990 and 2020. The indicator for this data is: 

###

Create an object named `ratio` and use the `WDI()` function to query the appropriate data. The `indicator` for this data is "BI.WAG.PRVS.FM.SM".

You should remember that unless we wish to know about a certain country, we should set `country` to "all"  You will need to specify a `start` and `end` year, as well as a language, `"en"` for English.

```{r wdi-01, exercise = TRUE}

```

```{r wdi-01-hint-1, eval = FALSE}
Use the WDIsearch() tool from the previous question if you are having 
difficulty locating the proper indicator. 
```

```{r wdi-01-hint-2, eval = FALSE}
ratio <- WDI(
  country = "all",
  indicator = ...,
  start = ...,
  end = ...,
  language = ...
)
```

###

NA values are common as some metrics are more difficult to measure consistently over time for various reporting, cooperation, or development issues among others. 

The output of the package WDI is ready to be coverted to a tibble by default.

### Exercise 3

Start a new pipe with `ratio` and begin creating a plot that answers our question. If we are interested in those countries that have the most closely aligned female and male wage allocations - we would expect the ratio to be 1.0.

###

Rename the indicator column to be `wage_ratio` and then drop NA values from the `wage_ratio` column. 

```{r wdi-02, exercise = TRUE}

```

```{r wdi-02-hint, eval = FALSE}
ratio %>% 
  mutate(wage_ratio = ...) %>% 
  drop_na(...)
```

### Exercise 4

Create a scatter plot that shows changes in the spread across countries over time.

```{r wdi-03, exercise = TRUE}

```

```{r wdi-03-hint, eval = FALSE}
... %>% 
  ggplot(aes(...)) +
  geom_point()
```

###

While this might be interesting, it is quite messy. 


### Exercise 5

The graph is too clutered. Filter the data to keep rows only where `country` is equal to Colombia, El Salvador, Honduras, Panama, the Philippines. Filter the data for only these countries

```{r wdi-04, exercise = TRUE}

```

```{r wdi-04-hint, eval = FALSE}
... %>% 
  filter(...) %>%
  ggplot(aes(...)) +
  geom_point()
```

###

Now we can start to see time trends within these countries. 


### Exercise 6

To make these trends easier to follow, connect the scatter-plot points with `geom_line()`. 

Be sure to add appropriate titles, labels, etc. 

```{r WDI-final, exercise = TRUE}

```

```{r WDI-final-hint, eval = FALSE}
... %>% 
  filter(...) %>%
  ggplot(aes(...)) +
  geom_point() +
  geom_line(aes(group = ...)) +
  scale_y_continuous(...) +
  labs(...)
```

### Exercise 7 

Use `labs()` to set an appropriate title, subtitle, axes labels, and captions.

```{r denver-15, exercise = TRUE}

```

###

Reminder: you plot should look like this: 

```{r final_plot_shown}
ratio_p
```

<!-- The remaining tasks to cover on this tutorial are to add more examples of API / API packages to reinforce the tools to find indicator codes and explore various open data offerings such that the tutorial takes 50-60 minutes. -->


## Submit

```{r context = "setup"}
submission_ui
```

```{r context = "server"}
submission_server()
```


