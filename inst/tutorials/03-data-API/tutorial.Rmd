---
title: "API"
tutorial:
  id: "data-api"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 3: Working with APIs"
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(httr)
library(WDI)
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

# Makes URL use simpler throughout the exercises. 

meso_url <- "https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"


```


<!-- Do not even mention API keys in the initial Query section. Too confusing! Instead, have the second section, called "API Keys" walk through the concept. 

This second section would show an example of using a key we provide in a call to a the API. First question, run GET without API key. Get back this failure. Sad! Then run this command with API key. Get back data. Cool! Then run `usethis::edit_r_environ()` -->

<!-- BM: unsure how to implement edit_r_environ in a useful way -->

<!-- > denver <- GET(url = meso_url) -->
<!-- > denver -->
<!-- Response [https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/] -->
<!--   Date: 2021-05-22 14:28 -->
<!--   Status: 500 -->
<!--   Content-Type: text/plain; charset=UTF-8 -->
<!--   Size: 23 B -->

<!-- > class(denver) -->
<!-- [1] "response" -->
<!-- >  -->

## Information
###

```{r information}
quiz(caption = "",
  question_text(
    "Name:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL),
  question_text(
    "Email:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL))
```

## Queries
###

In order to get data from an API, we use the **httr** package.


### Exercise 1

Load the `httr` package.  

```{r library, exercise = T}

```

```{r library-hint, eval = FALSE}
Use the library(...) command. 
```

### 

We now have access to the `httr` package. 


### Exercise 2

Because the Iowa Environmental Mesonet doesn't require us to use a user-specific API key, we can use a base URL to send an HTTP request. 

###

Create an object named `meso_url` that contains the URL listed in **Primer** chapter `3.6`. 

```{r create_url, exercise = TRUE}

```

```{r create_url-hint-1, eval = FALSE}
The URL should be a text string when being assigned to an object. 
```

```{r create_url-hint-2, eval = FALSE}
meso_url <- "your link here" 
```

###

<!-- In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. This is a simpler example of API use in which we don't need to protect a uniquely generated access key.  -->

You will now have access to this object throughout the rest of the tutorial. 


### Exercise 3

`GET()` is the key command in the **httr** package. It takes in the URL to the API and optionally a query to define the limits of the data accessed. 

###

Use `GET()` with the `url` argument set to `meso_url`. Assign the resulting object to `my.response`. In the second line, run `class()` on `my.response`.

```{r query-0, exercise = TRUE}

```

```{r query-0-hint, eval = FALSE}
my.response <- GET(url = ...)
```

```{r query-0-hint-2, eval = FALSE}
class(my.response)
```

###

Note that even without a query specification, the GET command appears to run but returns no data. 

### Exercise 4

Print out `my.response`. 

```{r query_01, exercise = TRUE}

```

```{r query_01-hint, eval = FALSE}
my.response
```

###

Note that the URL is the same as `meso_url`, which indicates that there was no further query. We can confirm that by looking at the size of the response - 23 Bytes. THe `Status: 500` indicates that the query encountered an error. 


### Exercise 5

Again, use `meso_url` to fill the `url` argument and then add the `query` argument set equal to a list of parameters which you wish to specify the parameters of your query. We want to know the temperature in Farenheight degrees in Denver, CO starting in 2017. Save the output as an object named `denver`. 

```{r query-1, exercise = TRUE}

```

```{r query-1-hint-1, eval = FALSE}
The abbreviation for temperature in F* is "tmpf".
```

```{r query-1-hint-2, eval = FALSE}
... <- GET(url = ...,
           query = list(station = ...,
                        data = "tmpf",
                        year1 = ...))
```

### 

There are several different types of data to be had from this API, including the temperature in degrees celsius, which come with different `data` query arguments. Notice that we still don't get data from this query. 

### Exercise 6

This API requires a start and end date (Year, Month, and Day) to be supplied in order to return a request successfully. 

###

You should extend `denver`to include the start and end point of your time frame - we are interested in the daily records between 2017 and 2019. You should also specify the appropriate time zone for the station listed. 

```{r query2, exercise = TRUE}

```

```{r query2-hint-1, eval = FALSE}

The start and end args. follow the naming system year1, year2, month1, month2 etc. 

The time zone for the Denver station is "America/Denver". 

```

```{r query2-hint-2, eval = FALSE}

denver <- GET(url = meso_url,
                    query = list(station = "DEN",
                                 data = "tmpf",
                                 year1 = "2017",
                                 month1 = ...,
                                 day1 = ...,
                                 year2 = "2019",
                                 month2 = ...,
                                 day2 = ...,
                                 tz = ...))

```

### Exercise 7

Now we have data!
Copy the code from the previous exercise without assigning it to an object. Note the size of the response - you should have ~7.98 MB of data. 

```{r query_resp1, exercise = TRUE}

```

```{r query_resp1-hint, eval = FALSE}
GET(url = meso_url,
    query = list(station = "DEN",
                 data = "tmpf",
                 year1 = "2017",
                 month1 = ...,
                 day1 = ...,
                 year2 = "2019",
                 month2 = ...,
                 day2 = ...,
                 tz = ...))
```

###

Now that we have data, we need to format it in a user-friendly way. 
Note that a successful query will show a small amount of the data below the response in addition to the `Status: 200` completion code and an extended URL that reflects the items in the query. 

### Exercise 8

This API allows us to download the data in CSV format. 

###

Set the query format argument equal to 'comma' (as in Comma Separated Variables). Then, to convert this data to a more familiar format, add the `content()` and `read_csv()` functions immediately following the `GET()` query to convert the jibberish from the query response into a nicely formatted tibble. Save this output as an object named 'denver'. 

```{r query-3, exercise = TRUE}

```

```{r query-3-hint, eval = FALSE}
denver <- GET(url = ...,
              query = list(...)) %>% 
  ... %>% 
  read_csv(... , ...)

Make sure that you properly address NA values - see Primer for examples. 
```

### 

Recall that the `content()` call extracts the content from the response to the HTTP request sent by the `GET()` function and allows us to parse the content like a traditional CSV file. 

### Exercise 9

Print out the `denver` object. 

```{r print_denver, exercise = TRUE}

```

###

You should see a normally formatted tibble, like we have dealt with in the last few weeks.

## Weather

We will now create the following plot of daily average temperatures in Denver, CO from 2017 to 2019. 

```{r get_denver_data}
denver <- GET(url = meso_url,
                    query = list(station = c("DEN"),
                                 data = "tmpf",
                                 year1 = "2017",
                                 month1 = "1",
                                 day1 = "1",
                                 year2 = "2019",
                                 month2 = "12",
                                 day2 = "31",
                                 tz = "America/Denver",
                                 format = "comma")) %>%
  content() %>% 
  read_csv(skip = 5, na = "M")
```

### Exercise 1

```{r make_plot_1}
denver_p <- denver %>% 
  separate(col = valid,
           into = c("date", NA),
           sep = " ") %>%
  group_by(date) %>%
  summarise(avg_temp = mean(tmpf, na.rm = TRUE),
            .groups = "drop") %>% 
  ggplot(aes(y = avg_temp,
                  x = date)) +
  geom_point() + 
  scale_x_discrete(breaks = c("2017-06-01", "2018-06-01", "2019-06-01")) +
  labs(x = NULL,
       y = "Average Temp. F*",
       title = "Daily Avg. Temperature in Denver, CO",
       caption = "Source: Iowa Environmental Mesonet")

denver_p
```

Beginning with the `denver` object that you created in the previous section, you will need to reformat the date slightly in order to calculate the daily avg. temperature. Using the `separate()` function, remove the timestamp from the given date variable and rename the remaining column "date". Save this as an object named `d1`

```{r plot-1, exercise = TRUE}

```

```{r plot-1-hint, eval = FALSE}

d1 <- denver %>% 
  separate(col = ...,
           into = c(..., NA),
           sep = ...)

```

###

The NA operator drops the second column from the separation - removing the need to select(-X) the unwnated data later. 

### Exercise 2

Now that we have a proper daily date column, extend the `d1` object's code to calculate the daily average temperature in a new column named "avg_temp". 

```{r plot-2, exercise = TRUE}

```

```{r plot-2-hint, eval = FALSE}

d1 <- denver %>% 
  separate(col = ...,
           into = c(..., NA),
           sep = ...) %>% 
  ... %>% 
  summarise(avg_temp = ...,
            .groups = "drop")


Be careful with NA values!

```


### 

Note the need to use na.rm = TRUE. 
This wrangling allows us to easily group by the daily timeseries rather than several times per hour. 
Now, you will have access to the `d1` object. 

### Exercise 3

Now that we have the desired calculations, create a scatterplot that maps average daily temperature to the y-axis and the date to the x-axis. 

```{r plot-3, exercise = TRUE}

```

```{r plot-3-hint, eval = FALSE}
d1 %>% 
  ggplot(aes(x = ..., y = ...)) +
  ...
```


### Exercise 4

Add Relevant titles and axis lablels as shown above - specifically be sure to use `scale_x_discrete()` to set the x axis labels to an inteligible state. 

```{r plot-4, exercise = TRUE}

```

```{r plot-4-hint, eval = FALSE}

d1 %>% ggplot(aes(y = ...,
                  x = ...)) +
  geom_point() + 
  scale_x_discrete(breaks = c(...)) +
  labs(x = ...,
       y = ...,
       title = ...,
       caption = ...)

```


## API Keys

In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. This is a simpler example of API use in which we don't need to protect a uniquely generated access key.

## The World Bank
###

The **WDI** package provides helper functions for accesses the API for the World Bank. You can learn more about the package [here](http://vincentarelbundock.github.io/WDI/). 


```{r wb_setup}
ratio <- WDI(
  country = "all",
  indicator = "BI.WAG.PRVS.FM.SM",
  start = 1990,
  end = 2020,
  # extra = FALSE,
  # cache = NULL,
  # latest = NULL,
  language = "en")

ratio_p <- ratio %>%
  rename(ratio = BI.WAG.PRVS.FM.SM) %>%
  drop_na(ratio) %>%
  filter(country %in% c("Colombia", "El Salvador", "Honduras",
                        "Panama", "Philippines")) %>%
  ggplot(aes(x = year, y = ratio, color = country)) +
  geom_point() +
  geom_line(aes(group = iso2c)) +
  
  # debating the best way to show the y-axis - 100% is an even distribution, but
  # I don't want to mislead the unattentive reader
  
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Female to Male Private Sector Wage Ratio",
    subtitle = "Women tend to earn more than men in Honduras",
    y = "Female-to-Male Wage Ratio",
    caption = "Source: The World Bank via the WDI API package",
    x = NULL,
    
    # Dropping the legend title
    
    color = NULL)

ratio_p

```



### Exercise 1

The most complex part of this edition of an API call on the World Bank's data is the data indicator - the obscure name string that selects the type of information pulled. Thankfully - there are some handy functions from the **WDI** package we can use. 

###

On the first line, load the **WDI** package. On the subsequent line, use `WDIsearch()` to look for indicator descriptions for "investment", and take a look at the results. 

```{r wdi-00, exercise = TRUE}

```

```{r wdi-00-hint, eval = FALSE}
library(WDI)
WDIsearch(...)[1:10,] 

# or

WDIsearch(...) %>% 
  head(...)
```

###

This works for an array of terms that the World Bank may have data about - feel free to explore! It is important to note the indicator of the data you wish to extract as it must be entered in your query. 

### Exercise 2

Will be looking at various countries and their private sector wage allocation between males and females, *as measured by the average group wage across business sectors* between 1990 and 2020. 

###

Create an object named `ratio` and use the `WDI()` function to query the appropriate data. 

You should remember that unless we wish to know about a certain country, we should query "all" countries. 

```{r wdi-01, exercise = TRUE}

```

```{r wdi-01-hint-1, eval = FALSE}
Use the WDIsearch() tool from the previous question if you are having 
difficulty locating the proper indicator. 
```

```{r wdi-01-hint-2, eval = FALSE}
ratio <- WDI(
  country = "all",
  indicator = ...,
  start = ...,
  end = ...,
  language = ...
)
```

###

Note that we also get the Country code along with the data and year as requested. 
NA values are common as some metrics are more difficult to measure consistently over time for various reporting, cooperation, or development issues among others. 

### Exercise 3

Now that we have our data, copy the code used above and begin creating a plot that answers our question. If we are interested in those countries that have the most closely aligned female and male wage allocations - we would expect the ratio to be 1.0.

###

Rename the indicator column to be `wage_ratio` and then drop NA values from the `wage_ratio` column. Be sure to reassign this change to `ratio`. 

```{r wdi-02, exercise = TRUE}

```

```{r wdi-02-hint, eval = FALSE}
ratio %>% 
  mutate(wage_ratio = ...) %>% 
  drop_na(...)
```

### Exercise 4

Create a scatter plot that shows changes in the spread across countries over time.

```{r wdi-03, exercise = TRUE}

```

```{r wdi-03-hint, eval = FALSE}
... %>% 
  ggplot(aes(...)) +
  geom_point()
```

###

While this might be interesting, it is quite messy. If you look closely there are many countries that only report for 3 or fewer years in our sample. 

A quick way to determine which countries are only reported for 1-3 years of the timeline is to use the `table()` function. `table(ratio$country)`, assuming that ratio has been filtered properly, shows the number of times that a given country shows up in the data being plotted. 


### Exercise 5

Analyzing those countries that show for $\geq7$ years in the above plot leaves us with 5 countries: Colombia, El Salvador, Honduras, Panama, the Philippines. Filter the data for only these countries

```{r wdi-04, exercise = TRUE}

```

```{r wdi-04-hint, eval = FALSE}
... %>% 
  filter(...) %>%
  ggplot(aes(...)) +
  geom_point()
```

###

Now we can start to see time trends within these countries. 


### Exercise 6

To make these trends easier to follow, connect the scatter-plot points with geom_line(). 

Be sure to add appropriate titles, labels, etc. 

```{r WDI-final, exercise = TRUE}

```

```{r WDI-final-hint, eval = FALSE}
... %>% 
  filter(...) %>%
  ggplot(aes(...)) +
  geom_point() +
  geom_line(aes(group = ...)) +
  scale_y_continuous(...) +
  labs(...)
```

###

Your plot should look mostly like this: 


```{r final_plot_shown}
ratio_p
```

<!-- The remaining tasks to cover on this tutorial are to add more examples of API / API packages to reinforce the tools to find indicator codes and explore various open data offerings such that the tutorial takes 50-60 minutes. -->


## Submit

```{r context = "setup"}
submission_ui
```

```{r context = "server"}
submission_server()
```
