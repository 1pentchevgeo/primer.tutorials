---
title: "API"
tutorial:
  id: "data-api"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 3: Working with APIs"
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(httr)
library(countrycode)
library(imfr)
library(rbison)
library(WDI)
library(plotly)
library(pageviews)
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

# Makes URL use simpler throughout the exercises. 

meso_url <- "https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"

my.response <- GET(url = meso_url) 

### IMF Objects

codes <- c("0", "GGXWDG_GDP", "P1Y")

imf_raw <- imf_data(database_id = "HPDD", indicator = "GGXWDG_GDP", 
                     start = 2014)

imf_data <- imf_raw %>% 
  filter(year == "2015")

iso_codes <- codelist %>% 
  select(iso2c, country.name.en)

imf_data_named <- left_join(imf_data, iso_codes, by = "iso2c")
```


<!-- Do not even mention API keys in the initial Query section. Too confusing! Instead, have the second section, called "API Keys" walk through the concept. 

This second section would show an example of using a key we provide in a call to a the API. First question, run GET without API key. Get back this failure. Sad! Then run this command with API key. Get back data. Cool! Then run `usethis::edit_r_environ()` -->

<!-- BM: unsure how to implement edit_r_environ in a useful way -->

<!-- > denver <- GET(url = meso_url) -->
<!-- > denver -->
<!-- Response [https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/] -->
<!--   Date: 2021-05-22 14:28 -->
<!--   Status: 500 -->
<!--   Content-Type: text/plain; charset=UTF-8 -->
<!--   Size: 23 B -->

<!-- > class(denver) -->
<!-- [1] "response" -->
<!-- >  -->

## Information
###

```{r information}
quiz(caption = "",
  question_text(
    "Name:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL),
  question_text(
    "Email:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL))
```

## Iowa Mesonet
###

In order to get data from an API, we use the **httr** package.


### Exercise 1

Load the `httr` package.  

```{r library, exercise = T}

```

```{r library-hint, eval = FALSE}
Use the library(...) command. 
```

### 

We now have access to the `httr` package. 


### Exercise 2

Because the Iowa Environmental Mesonet doesn't require us to use a user-specific API key, we can use a base URL to send an HTTP request. 

###

Assign the url in your code to an an object named `meso_url`. 

```{r create_url, exercise = TRUE}
"https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"

```

```{r create_url-hint-1, eval = FALSE}
The URL should be a text string when being assigned to an object. 
```

```{r create_url-hint-2, eval = FALSE}
meso_url <- "https://..." 
```


###

<!-- In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. This is a simpler example of API use in which we don't need to protect a uniquely generated access key.  -->

You will now have access to this object throughout the rest of the tutorial. The **base URL** allows you to send a request and specify the subset of data you want. 


### Exercise 3

`GET()` is the key command in the **httr** package. It takes in the URL to the API and optionally a query to define the limits of the data accessed. 

###

Use `GET()` with the `url` argument set to `meso_url`. Assign the resulting object to `my.response`. In the second line, run `class()` on `my.response`.

```{r query-0, exercise = TRUE}

```

```{r query-0-hint, eval = FALSE}
my.response <- GET(url = ...)
```

```{r query-0-hint-2, eval = FALSE}
class(my.response)
```

###

Note that even without a query specification, the GET command appears to run but returns no data. You get an object of `class()` "response" because you are still communicating with the base url. 

### Exercise 4

Print out `my.response`. 

```{r query_01, exercise = TRUE}

```

```{r query_01-hint, eval = FALSE}
my.response
```

###

Note that the URL is still the base url, which indicates that there was no further query. We can confirm that by looking at the size of the response - 23 Bytes. THe `Status: 500` indicates that the query encountered an error. 


### Exercise 5

Within the function `GET()`, use `meso_url` to fill the `url` argument and then set the argument `query` equal to a `list()` of parameters: `station`, `data`, `year1`.  We want to know for station Denver (`"DEN"`) the temperature in degrees Fahrenheit (`"tpmf"`) starting in the year 2017. 

```{r query-1, exercise = TRUE}

```

```{r query-1-hint-1, eval = FALSE}
The abbreviation for temperature in Fahrenheit is "tmpf".
```

```{r query-1-hint-2, eval = FALSE}
GET(url = ...,
           query = list(station = ...,
                        data = "tmpf",
                        year1 = ...))
```

### 

There are several different types of data to be had from this API, including the temperature in degrees celsius, which come with different `data` query arguments. 

### Exercise 6

This API requires a start and end date (Year, Month, and Day) to be supplied in order to return a request successfully. 

###

Copy and paste the code from the previous exercise. Within `GET()`, you should add parameters to include the start, `year1` `month1` `day1`, and end point of your time frame, `year2` etc. We are interested in the daily records from 01/01/2017 to 12/31/2019. You should also specify the appropriate time zone for the station listed. The time zone for the Denver station is "America/Denver". 

```{r query2, exercise = TRUE}

```

```{r query2-hint-1, eval = FALSE}
All date parameters should be quoted numbers
i.e. "01" is January.
```

```{r query2-hint-2, eval = FALSE}
GET(url = meso_url,
    query = list(station = "DEN",
                 data = "tmpf",
                 year1 = "2017",
                 month1 = ...,
                 day1 = ...,
                 year2 = "2019",
                 month2 = ...,
                 day2 = ...,
                 tz = ...))
```

<!-- Here we should probably keep assignment and have them call a denver programmed in the set_up chunk?  -->

### Exercise 7

Copy the code from the previous exercise and assign the output to `denver`.   

```{r query_resp1, exercise = TRUE}

```

```{r query_resp1-hint, eval = FALSE}
denver <- GET(url = meso_url,
              query = list(station = "DEN",
                           data = "tmpf",
                           year1 = "2017",
                           month1 = "01",
                           day1 = "01",
                           year2 = "2019",
                           month2 = "12",
                           day2 = "31",
                           tz = "America/Denver"))
```

###

Now that we have data, we need to format it in a user-friendly way.  Note that a successful query will show a small amount of the data below the response in addition to the `Status: 200` completion code and an extended URL that reflects the items in the query. 

### Exercise 8

This API allows us to download the data in CSV format. 

###

Within the `list()` for `query`, set `format`  equal to `comma` (as in Comma Separated Variables). Then, to convert this data to a more familiar format, add the `content()` and `read_csv()` functions immediately following the `GET()` query to convert the gibberish from the query response into a tibble. 

```{r query-3, exercise = TRUE}

```

```{r query-3-hint, eval = FALSE}
GET(url = ...,
              query = list(...,
                           format = "comma")) %>% 
  content() %>% 
  read_csv(... , ...)

Make sure that you properly address NA values - see Primer for examples. 
```

### 

Recall that the `content()` call extracts the content from the response to the HTTP request sent by the `GET()` function and allows us to parse the content like a traditional CSV file. 

### Exercise 9

The many Ms is this dataset's way of representing missing values. Within `read_csv()`, use the `na` argument to change all occurrences of the lone character `"M"` to `NA`.Save this output as an object named 'denver'. 

```{r query-10, exercise = TRUE}

```

```{r query-10-hint-1, eval = FALSE}
GET(url = ...,
              query = list(...,
                           format = "comma")) %>% 
  content() %>% 
  read_csv(... , ...)
```

### Exercise 10

Print out the `denver` object. 

```{r print_denver, exercise = TRUE}

```

###

You should see a normally formatted tibble, like we have dealt with in the last few weeks.

```{r get_denver_data}
denver <- GET(url = meso_url,
                    query = list(station = c("DEN"),
                                 data = "tmpf",
                                 year1 = "2017",
                                 month1 = "1",
                                 day1 = "1",
                                 year2 = "2019",
                                 month2 = "12",
                                 day2 = "31",
                                 tz = "America/Denver",
                                 format = "comma")) %>%
  content() %>% 
  read_csv(skip = 5, na = "M")
```

### Exercise 11

Let's use the data to make the following plot. 

```{r make_plot_1}
denver_p <- denver %>% 
  separate(col = valid,
           into = c("date", NA),
           sep = " ") %>%
  group_by(date) %>%
  summarise(avg_temp = mean(tmpf, na.rm = TRUE),
            .groups = "drop") %>% 
  ggplot(aes(y = avg_temp,
                  x = date)) +
  geom_point() + 
  scale_x_discrete(breaks = c("2017-06-01", "2018-06-01", "2019-06-01")) +
  labs(x = NULL,
       y = "Average Temp. F*",
       title = "Daily Avg. Temperature in Denver, CO",
       caption = "Source: Iowa Environmental Mesonet")

denver_p
```

Let's remove the timestamp from the given date variable and rename the remaining column "date". Within the function `separate()`, use the argument `col` to select which column's content you are separating, use the argument `into` to create a vector of the new column names, `"date"` and `NA`, and use the third argument to show by what character you are separating the data `" "`.  Save this as an object named `d1`

```{r plot-11, exercise = TRUE}

```

```{r plot-11-hint, eval = FALSE}

d1 <- denver %>% 
  separate(col = valid,
           into = c(..., NA),
           sep = " ")

```

###

The NA operator drops the second column from the separation - removing the need to select(-X) the unwanted data later. 

### Exercise 12

The date column has multiple rows for the same day. Continue your pipe and use `group_by()` and `summarize()` to calculate the daily average temperature in a new column named "avg_temp". 

```{r plot-2, exercise = TRUE}

```

```{r plot-2-hint-1, eval = FALSE}
Within the `mean()` function, set `na.rm` to TRUE 
to remove NA values from calculation. 
```

```{r plot-2-hint-2, eval = FALSE}

d1 <- denver %>% 
  separate(col = ...,
           into = c(..., NA),
           sep = ...) %>% 
  ... %>% 
  group_by(...) 
  summarise(avg_temp = ...,
            .groups = "drop")


Be careful with NA values!

```


###

Now, you will have access to the `d1` object. 

### Exercise 13

Now that we have the desired calculations, start a new pipe with `d1` and create a scatterplot that maps average daily temperature to the y-axis and the date to the x-axis. 

```{r plot-3, exercise = TRUE}

```

```{r plot-3-hint, eval = FALSE}
d1 %>% 
  ggplot(aes(x = ..., y = ...)) +
  geom_point()
  ...
```

### Exercise 14

There are so many labels for x-axis breaks that they are indistiguishable. Use `scale_x_discrete()` to set only three x axis breaks, `06-01-2017`, `06-01-2018`, `06-01-2019`.

```{r plot-4, exercise = TRUE}

```

```{r plot-4-hint, eval = FALSE}

d1 %>% ggplot(aes(y = ...,
                  x = ...)) +
  geom_point() + 
  scale_x_discrete(breaks = c(...)) 
```

### Exercise 15

Use `labs()` to set an appropriate title, subtitle, caption, axes labels, and captions.

```{r denver-15, exercise = TRUE}

```

Reminder: The graph should look like this

```{r show-denver-p}
denver_p
```


## API Keys

In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. The following are examples of examples of API use in which we don't need to protect a uniquely generated access key.

## Wikipedia Page Access
###

The **pageviews** package provides helper functions for accesses the API for the World Bank. You can learn more about the package [here](https://cran.rstudio.com/web/packages/pageviews/pageviews.pdf). 


```{r supreme_setup}
supreme_views <- old_pageviews(project = "en.wikipedia",
                           article = "Supreme_Court_of_the_United_States",
                           platform = "all",
                           user_type = "all",
                           start = "2008012000",
                           end = "2016012000") 

supreme_plot <- supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("Date:", date, "\n"))) +
  geom_col() +
  labs(title = "Wikipedia Supreme Court Page During Pres. Obama's Tenure",
       x = "Date", 
       y = "Views", 
       caption = "Wikimedia Traffic Data API")

final <- ggplotly(supreme_plot, tooltip = "text")

final
```



### Exercise 1

On the first line, load the **pageviews** package. In this package, the functions `article_pageviews()` and `old_pageviews()` allow us to communicate with the Wikimedia API. 

```{r supreme-01, exercise = TRUE}

```

```{r supreme-01-hint, eval = FALSE}
library(pageviews)
```

###

`old_pageviews()` is for counts before 2016. They are not accurate as they did not omit the activity of web-crawlers and bots.

### Exercise 2

We will be looking at the wikipedia page views for the Supreme Court of the United States countries during President Obama's tenure, from January 20th 2008 to January 20th 2016.

###

Start a call with `old_pageviews()`. Set the `project` argument equal to `wikipedia.en` and the article to `Supreme_Court_of_the_United_States`. Set the start time and end time in the format: YYYYMMDDHH. Set hours to 00, they do not matter as the granularity is by default daily. Assign this to an object called `supreme_views`.

```{r supreme-02, exercise = TRUE}

```

```{r supreme-02-hint-1, eval = FALSE}
Use the WDIsearch() tool from the previous question 
if you are having difficulty locating the proper 
indicator. 
```

```{r supreme-02-hint-2, eval = FALSE}
old_pageviews(project = "en.wikipedia",
                           article = "Supreme_Court_of_the_United_States",
                           start = "2008012000",
                           end = "2016012000") 
```

###

Because this is a package designed to work with this API, we do not need to use a base url. Also, the output of the function is made into a tibble by default.

### Exercise 3

Start a new pipe with `supreme_views`. Use `ggplot()` and `geom_col()` to make a bar graph with `date` on the x-axis and `views()` on the y axis. 

```{r supreme-03, exercise = TRUE}

```

```{r supreme-03-hint, eval = FALSE}
supreme_views %>% 
  ggplot(aes(..., ,...)) +
  geom_col()
```

### Exercise 4

Use the `text` argument and the function `paste()` to create a label which you can use for plotly.

```{r supreme-04, exercise = TRUE}

```

```{r supreme-04-hint-1, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("...", ..., "\n"))) +
  geom_col()
```

```{r suoreme-04-hint-2, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("Date:", date, "\n"))) +
  geom_col()
```

###

### Exercise 5

Use `labs()` to set an appropriate title, caption, and axes labels

```{r supreme-05, exercise = TRUE}

```

### Exercise 6

Copy/paste your code. Assign the output of the pipe to an object called `supreme_plot`.

```{r supreme-06, exercise = TRUE}

```

### Exercise 7 

Use the function `ggplotly()` to add interactive labels to supreme_plot.

```{r supreme-07, exercise = TRUE}

```

```{r supreme-07-hint-1, eval = FALSE}
ggplotly(..., tooltip = "text")
```

```{r suoreme-07-hint-2, eval = FALSE}
ggplotly(..., tooltip = "text")
```


Reminder: you plot should look like this: 

```{r show-supreme-plot}
final
```

<!-- The remaining tasks to cover on this tutorial are to add more examples of API / API packages to reinforce the tools to find indicator codes and explore various open data offerings such that the tutorial takes 50-60 minutes. -->

## The World Bank
###

The **WDI** package provides helper functions for access to the API for the World Bank. You can learn more about the package [here](http://vincentarelbundock.github.io/WDI/). 


```{r wb_setup}
ratio <- WDI(
  country = "all",
  indicator = "BI.WAG.PRVS.FM.SM",
  start = 1990,
  end = 2020,
  language = "en")

ratio_p <- ratio %>%
  rename(ratio = BI.WAG.PRVS.FM.SM) %>%
  drop_na(ratio) %>%
  filter(country %in% c("Colombia", "El Salvador", "Honduras",
                        "Panama", "Philippines")) %>%
  ggplot(aes(x = year, y = ratio, color = country)) +
  geom_point() +
  geom_line(aes(group = iso2c)) +
  
  # debating the best way to show the y-axis - 100% is an even distribution, but
  # I don't want to mislead the unattentive reader
  
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Female to Male Private Sector Wage Ratio",
    subtitle = "Women tend to earn more than men in Honduras",
    y = "Female-to-Male Wage Ratio",
    caption = "Source: The World Bank via the WDI API package",
    x = NULL,
    
    # Dropping the legend title
    
    color = NULL)

ratio_p

```


### Exercise 1

The most complex part of this edition of an API call on the World Bank's data is the data indicator - the obscure name string that selects the type of information pulled. Thankfully - there are some handy functions from the **WDI** package we can use. 

###

On the first line, load the **WDI** package. On the subsequent line, use `WDIsearch()` to search indicator descriptions for "investment", and take a look at the first ten results.

```{r wdi-00, exercise = TRUE}

```

```{r wdi-00-hint, eval = FALSE}
library(WDI)
WDIsearch(...)[1:10,] 

# or

WDIsearch(...) %>% 
  head(...)
```

###

This works for an array of terms that the World Bank may have data about - feel free to explore! It is important to note the indicator of the data you wish to extract as it must be entered in your query. 

### Exercise 2

Will be looking at various countries and their private sector wage allocation between males and females, *as measured by the average group wage across business sectors* between 1990 and 2020. The indicator for this data is: 

###

Create an object named `ratio` and use the `WDI()` function to query the appropriate data. The `indicator` for this data is "BI.WAG.PRVS.FM.SM".

You should remember that unless we wish to know about a certain country, we should set `country` to "all"  You will need to specify a `start` and `end` year, as well as a language, `"en"` for English.

```{r wdi-01, exercise = TRUE}

```

```{r wdi-01-hint-1, eval = FALSE}
Use the WDIsearch() tool from the previous question if you are having 
difficulty locating the proper indicator. 
```

```{r wdi-01-hint-2, eval = FALSE}
ratio <- WDI(
  country = "all",
  indicator = ...,
  start = ...,
  end = ...,
  language = ...
)
```

###

NA values are common as some metrics are more difficult to measure consistently over time for various reporting, cooperation, or development issues among others. 

The output of the package WDI is ready to be coverted to a tibble by default.

### Exercise 3

Start a new pipe with `ratio` and begin creating a plot that answers our question. If we are interested in those countries that have the most closely aligned female and male wage allocations - we would expect the ratio to be 1.0.

###

Rename the indicator column to be `wage_ratio` and then drop NA values from the `wage_ratio` column. 

```{r wdi-02, exercise = TRUE}

```

```{r wdi-02-hint, eval = FALSE}
ratio %>% 
  mutate(wage_ratio = ...) %>% 
  drop_na(...)
```

### Exercise 4

Create a scatter plot that shows changes in the spread across countries over time.

```{r wdi-03, exercise = TRUE}

```

```{r wdi-03-hint, eval = FALSE}
... %>% 
  ggplot(aes(...)) +
  geom_point()
```

###

While this might be interesting, it is quite messy. 


### Exercise 5

The graph is too clutered. Filter the data to keep rows only where `country` is equal to Colombia, El Salvador, Honduras, Panama, the Philippines. Filter the data for only these countries

```{r wdi-04, exercise = TRUE}

```

```{r wdi-04-hint, eval = FALSE}
... %>% 
  filter(...) %>%
  ggplot(aes(...)) +
  geom_point()
```

###

Now we can start to see time trends within these countries. 

### Exercise 6

To make these trends easier to follow, connect the scatter-plot points with `geom_line()`. 

Be sure to add appropriate titles, labels, etc. 

```{r WDI-final, exercise = TRUE}

```

```{r WDI-final-hint, eval = FALSE}
... %>% 
  filter(...) %>%
  ggplot(aes(...)) +
  geom_point() +
  geom_line(aes(group = ...)) +
  scale_y_continuous(...) +
  labs(...)
```

### Exercise 7 

Use `labs()` to set an appropriate title, subtitle, axes labels, and captions.

```{r denver-7, exercise = TRUE}

```

###

Reminder: you plot should look like this: 

```{r final_plot_shown}
ratio_p
```

## The International Monetary Fund
###

Let's make the following plot with data from the Internation Monetary Fund API. 

```{r show-plot}
imf_plot <- imf_data_named %>% 
  rename(dtg = `GGXWDG_GDP`) %>% 
  arrange(desc(dtg)) %>% 
  slice(1:15) %>% 
  ggplot(aes(x = dtg,  y = fct_reorder(country.name.en, dtg))) +
  geom_col() +
  labs(title = "15 Countries of the Highest Debt to Income Ratios in 2015", 
       subtitle = "The United States of America is in 12th Place",
       x = "Debt to GDP Ratio", 
       y = "",
       caption = "International Monetary Fund")

imf_plot
```

###

The **imfr** package provides helper functions for access to the API for the International Monetary Fund. You can learn more about the package [here](https://github.com/christophergandrud/imfr.)

### Exercise 1

Load the `imfr` pacakge. 

```{r imfr-1, exercise = TRUE}

```

```{r imfr-1-hint, eval = FALSE}
library(imfr)
```

### Exercise 2

Let's learn more about the `imfr` package. In your console, run `help(package = "imfr")`. Click and read about the function `imf_data`, the function used to download data in this package.

```{r imfr-2, exercise = TRUE}

```

```{r imfr-2-hint, eval = FALSE}
help(pacakge = "imfr")
```

We see that `imf_data` requires two arguments. A `database_id` which can be found with the function `imf_ids` and a string or vector of indicator IDs which can be found in the function `imf_codes`. 

###
 
At the bottom of the help page we can find example uses of the functions. There we see examples both where `indicator` is set equal to one string and to a vector of strings. 

### Exercise 3 

Use the back button at the top left corner of the help pane to navigate to the previous page. Read the page `imf_ids` and `imf_codes`. 

```{r imfr-3, exercise = TRUE}

```

###

Both functions return a data frame. `imf_ids` requires no arguments, but `imf_codes` requires a codelist argument which we can get from the function `imf_codelist`. 

###

If a help page function has an argument with nothing equal to it, that means there is no default for that argument and that the user must specify the value.

### Exercise 4

Use the back button at the top left corner of the help pane to navigate to the previous page. Read about `imf_codelist`.

```{r imfr-4, exercise = TRUE}

```

###

`imf_codelist` also returns a data frame of codelist codes and their descriptions. It requires the argument `database_id`. 

### Exercise 5

Run the function `imf_ids()`. Explore this tibble. On page three we see a row with the description "Historical Public Debt" with the code "HPDD". 

```{r imfr-5, exercise = TRUE}

```

```{r imfr-5-hint, eval = FALSE}
imf_ids()
```

### Exercise 6

Run the function `imf_codelist()` with the argument "HPDD". One item has the description `Indicator` which was the name for the argument in `imf_data()`.

```{r imfr-6, exercise = TRUE}

```

```{r imfr-6-hint, eval = FALSE}
imf_ids("HPDD")
```

### Exercise 7 

Run the function `imf_codes()` with the argument being the indicator codelist, "CL_INDICATOR_HPDD". 

```{r imfr-7, exercise = TRUE}

```

```{r imfr-7-hint, eval = FALSE}
imf_codes("CL_INDICATOR_HPDD")
```

###

There is only code, "GGXWDG_GDP", which has a description "Debt to GDP Ratio". 

### Exercise 8

Run the function `imf_data()`. Set the first argument `database_id` equal to "HPDD". Set the second argument `indicator` equal to "GGXWDG_GDP". Set start equal to 2014. Save this to an output called `imf_raw`.

```{r imfr-8, exercise = TRUE}
imf_data(database_id = "HPDD", indicator = "GGXWDG_GDP", 
         start = 2014, end = 2015)
```

Recall in the help page that the argument `country` has a default value of "all" and that the argument `freq` has a default value of "A" for annual.  

### Exercise 9

Start a new pipe with `imf_raw`. Let's see how many years were included in this output. Arrange the tibble in descending order by `year`. 

```{r imfr-9, exercise = TRUE}

```

```{r imfr-9-hint, eval = FALSE}
imf_data(database_id = "HPDD", indicator = "GGXWDG_GDP", start = 2014) %>% 
  arrange(desc(year))
```

###

The data has a max year of 2015, even though the argument `end` is set by default to `current_year()`.

### Exercise 10

Copy and filter the data to keep rows only where year is equal to "2015". Assign this to an object named `imf_data`. 

```{r imfr-10, exercise = TRUE}

```

```{r imfr-10-hint, eval = FALSE}
imf_data %>% 
  arrange(desc(year))
```

### Exercise 11

There is a package called `countrycode`. In the console, run `help(package == "countrycode")` to bring up the help page for this package. Click on the function `codelist`.

```{r imfr-11, exercise = TRUE}

```

```{r imfr-11-hint, eval = FALSE}
imf_data %>% 
  filter(year == "2015")
```

###

We found out about the package `countrycode` by reading the page for the function `all_iso2c` on the `imfr` help page. 

### Exercise 12

Run `codelist`. Check to see if there is an iso2c column in this tibble. 

```{r imfr-12, exercise = TRUE}

```

```{r imfr-12-hint, eval = FALSE}
codelist
```

### Exercise 13

Select the columns `iso2c` and `country.name.en`. Save this to an object called `iso_codes`. 

```{r imfr-13, exercise = TRUE}

```

```{r imfr-13-hint, eval = FALSE}
iso_codes <- codelist %>% 
  select(..., ...)
```

### Exercise 14

Use `left_join()` to join `iso_codes` to `imf_data` by the shared column `iso2c`. Save this to an object named imf_data_named.   

```{r imfr-14, exercise = TRUE}

```

```{r imfr-14-hint, eval = FALSE}
left_join(imf_data, iso_codes, by = "...")
```

### Exercise 15

Let's check if any countries have not been matched to a `country.name.en`. Run the command `is.na()` with the argument being the column `iso2c` as a vector.

```{r imfr-15, exercise = TRUE}

```

```{r imfr-15-hint-1, eval = FALSE}
Remember that we use the $ operator to extract a column as a vector.
```

```{r imfr-15-hint, eval = FALSE}
is.na(imf_data_named$country.name.en)
```

### Exercise 16 

It is hard to see whether there are any values of `TRUE` in so large a vector. Copy and paste the previous code. Pipe the function `table()` to it. 

```{r imfr-16, exercise = TRUE}

```

```{r imfr-16-hint, eval = FALSE}
is.na(imf_data_named$iso2c) %>% 
  table()
```

### 

Every country was able to be matched to a value in `country.name.en` through the column `iso2c`. 

### Exercise 17

Start a new pipe with imf_data_named. Rename the column `GGXWDG_GDP` to `dtg`. When referring to columns that begin with capital letters, numbers, or special characters in code, you must surround them with bacticks, e.g. "`GGXWDG_GDP`".

```{r imfr-17, exercise = TRUE}

```

```{r imfr-17-hint, eval = FALSE}
rename(... =  = `GGXWDG_GDP`)
```

### Exercise 18

Arrange the column in descending order by `dtg`. Use `slice()` to select the rows with the 15 countries with the highest debt to gdp ratios, i.e. the first fifteen rows.

```{r imfr-18, exercise = TRUE}

```

```{r imfr-18-hint, eval = FALSE}
... %>% 
  arrange(desc(dtg)) %>% 
  slice(1:15)
```

### Exercise 19 

Continue your pipe with `ggplot()`. Map `dpg` to the x-axis and `country.name.en` to the y-axis. Add the layer `geom_col()`. 

```{r imfr-19, exercise = TRUE}

```

```{r imfr-19-hint, eval = FALSE}
... %>% 
  ggplot(mapping = aes(x = ..., y = ...)) 
```

###

You will have a plot with nothing drawn because you have not added a `geom` layer. 

### Exercise 20

Let's reorder the order of the countries on the y axis. Within `ggplot()` set `y` equal to the function `fct_reorder()`. The first argument should be the current y-axis variable, `country.name.en`. The second argument should be the variable by which we want to order the countries, `dtg`. 

```{r imfr-20, exercise = TRUE}

```

```{r imfr-20-hint, eval = FALSE}
... +
  ggplot(mapping = aes(x = dpg, y = fct_reroder(country.name.en, dpg))) 
```

### Exercise 21

Use the layer `labs()` to add a title, subtitle, and axes labels to your plot. 

```{r imfr-21, exercise = TRUE}

```

```{r imfr-21-hint, eval = FALSE}
... +
  labs(...,
       y = ""
       ...)
```

Reminder: Your graph should look like this

```{r show-imf-plot}
imf_plot
```


## Submit

```{r context = "setup"}
submission_ui
```

```{r context = "server"}
submission_server()
```


