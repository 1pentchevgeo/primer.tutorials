---
title: Mapping
tutorial:
  id: mapping
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: Mapping data in R
---


```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(primer.data)
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 
```

```{r copy-code-chunk, child = "../../child_documents/copy_button.Rmd"}
```

```{r info-section, child = "../../child_documents/info_section.Rmd"}
```

<!-- CHECKLIST BEFORE STARTING: -->
<!-- * Load necessary libraries for tutorial in the first code chunk -->
<!-- * Edit yaml at the START OF THIS FILE -->
<!-- * Review: https://ppbds.github.io/primer.tutorials/articles/instructions.html -->


<!-- ## First section (use sentence case) -->
<!-- ### -->

## Setup project
###

In this tutorial, we're going to be creating maps based off of US Census Bureau data. We'll be utilizing commands from the "Downloading Census Data" tutorial in order to do this, so please do that tutorial before starting on this one.

### Exercise 1

<!-- AG: I'm going to have them publish the maps because it's cool. These are the ramblings of a guy who's running on 4 hours of sleep though, so feel free to change it. -->

Let's start a new R project so that we can create and eventually publish our maps.

###

<!-- AG: Don't know what the syntax is for repo naming in the Primer, I think this is it. -->

Create a new GitHub repo titled `mapping-in-r` and link it to your RStudio like you have done so far. Remember to update the `.gitignore` file.

###

<!-- AG: Should we use terminal or console commands for this tutorial? I'm going with console for now since I'm way too used it after the RStudio and Friends tutorial. -->

Run `list.files()` in the Console to list all of the files. Copy and paste the output into the space below.

```{r setup-1}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 2))
```

###

We'll be working in this project for the rest of this tutorial.

### Exercise 2

Create a new R Markdown file titled `index.Rmd` and delete all of the things except for the setup chunk and the YAML header.

###

Run `list.files()` in the Console to list all of the files. Copy and paste the output into the space below.

```{r setup-1}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 2))
```

###

This should include the R Markdown file you created at the bottom.

## Mapping basics
###

You've likely heard of longitude and latitude, the global coordinate system that lets us pinpoint 2D locations on a 3D surface. This is also known as a **c**oordinate **r**eference **s**ystem, or **CRS**. CRSs use a 3D model of the Earth to define locations on the surface of a grid, with longitude determining the east/west distance and the latitude determining the north/south distance. 

###

CRS are used to define spatial data that we can then map. 

###

Spatial data with a defined CRS can either be vector or raster data. Vector data is based on points that can be connected to form lines and polygons. It is located within a coordinate reference system and is similar to what a roadmap would look like.

###

Raster data, however, are values within a grid system, such as satellite imagery. In this Primer, we will only be dealing with vector data, which is the format in which we get data from the **tidycensus** package.

###

In order to parse this information, we will be using the **sf** package to process vector data. The **sf** package stores data in data frames, allowing us to use the **dbplyr** methods that we're familiar with.

### Exercise 1

While R can handle a large amount of file formats for spatial data, we'll be focusing on shape files. While we refer to them as a "shapefile", it's actually composed of 3 basic files: `.shp` files for the shape and vertices, `.shx` files for indexes and offsets, and `.dbf` files to connect the geometry and the data. Luckily, this is already dealt with by **tidycensus** when it imports the Census shapefile.

###

In order to start mapping in R, we need to get a little more data from the **tidycensus** package. In particular, we need to set geometry = TRUE.

###

Add a new code chunk into your R Markdown file and add the `get_decennial()` function into it. Set the argument `geography` to `"state"`, `variables` to `"P001001"` and `"P002005"`, `year` to `2010`, `output` to `"wide"`, and `geometry` to `TRUE`.

Run `list.files()` in the Console to list all of the files. Copy and paste the output into the space below.

```{r basics-1}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 2))
```

###

<!-- AG: Can we link tutorials together? -->

We covered this command in the Downloading Census Data tutorial. If you don't know what to type, please do that tutorial first before starting on this one.

### Exercise 2





```{r download-answers, child = "../../child_documents/download_answers.Rmd"}
```
