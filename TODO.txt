TO-DO Items for Tutorials

* Function B:

Beware error = TRUE.

Only one stopifnot(length(guesses) == 2). Other check is too hard.

Why not write a script first, like we did in the first question. Then put it in a function. Then pull out the arguments?

Use fewer setup chunks.

Check out my changes.

* Reading chapter 3, cleaning up, cleaning tutorial. Go through the questions to ensure that they are still covered in our simplified chapter.


* Add two or three questions about Scaling distributions to Wrangling D.

* Do first 4 questions in this tutorial.

https://minecr.shinyapps.io/dsbox-05-moneyinpolitics/

To Discuss:




* Can we show "answers" to a Tutorial after students have submitted it? How? Maybe all we need is a script which pulls out the code for all the major examples and puts it in a single RMD which we could knit and distribute? If we had a standard scheme for naming the R code chunks in which these are created, pulling them out would be easy. Indeed, creating this file could be part of the test process!

What is up with this note?

* checking dependencies in R code ... NOTE
Namespaces in Imports field not imported from:
  ‘grid’ ‘png’ ‘primer.data’ ‘readxl’ ‘rstanarm’ ‘tidyverse’
  All declared Imports should be used.


Plots in visualization-D with vertical lines for 2* mad .

Get .Rbuildignore to ignore any non-Rmd file in inst/tutorials. Otherwise, the tutorial folder gets too big with all the junk files.

Automate a test of the Submit button. Want to actually download the rds and check that it is "correct."


* Add this to instructions:

In many settings, it is natural for a tools question to have three parts. First, run a line of code that reports on the value of something. Example:

rstudioapi::readRStudioPreference(name = "load_workspace", default = "Code failed.")

This will return the defaul value. (I am not what that is.)

Second, change the setting. This generally won't return anything.

rstudioapi::writeRStudioPreference(name = "load_workspace", value = FALSE)

See how the first was "read" and the second was "write"? Then, the third and final step is to confirm that the change worked by re-running the first code again.

rstudioapi::readRStudioPreference(name = "load_workspace", default = "Code failed.")

And finish with a sentence that tells the student to notice that the value has changed and that it is now correct. (Of course, we "monitor" that by making them copy/paste this last command and its return from the Console into the tutorial.)


* What to do with PDF and tinytex? This all seemed to work very easily. Maybe just install and then issue packageVersion("tinytex")?

* mention iter = 10000

* Revisit making tables nice.


________________________________

To Explore:


* Explore the use of setup chunks that are referenced by name, rather than requiring that the code chunk names match up. Example: exercise.setup = "setupA"

* Put the number of exercises in the group header so that students know how long? Or maybe put in in the exercise header in exercise 5, 10 and so on.

* Can we do web-scraping in a tutorial?

* Can we give students a search box in the tutorial so that they can find answers to questions they have already done?

* There is a lot of redundent text in tutorials: Write your name, submit, et cetera. Any way to avoid copying/pasting that each time? Maybe we need a "make tutorial" script which would take a raw tutorial and then add that material to it. Perhaps a template? But then we can't (?) go back and make a change in our other 20 tutorials.

* Have our testing process check that all hints have eval = FALSE.

* How test for exercise chunks with no lines, which causes a weird error?

* Interesting discussion and some plausible claims: http://laderast.github.io/2020/09/15/getting-learnr-tutorials-to-run-on-mybinder-org/. Claims that "the .Rmd file containing the tutorial should be named the same as the directory it is in." But why?


* https://github.com/karthik/holepunch is interesting.




